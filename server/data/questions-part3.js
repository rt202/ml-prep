// Part 3: NLP, Computer Vision, Feature Engineering, Model Evaluation, SQL
export const questionsPart3 = [
  // ====== UNIT: nlp ======
  // Lesson: nlp-basics
  { id: 'nlp-1', text: 'What is tokenization in NLP?', options: ['Converting text to numbers', 'Breaking text into smaller units (words, subwords, or characters) for processing by NLP models', 'Encrypting text data', 'Removing stop words'], correctAnswer: 1, explanation: 'Tokenization splits text into tokens—words, subwords, or characters. Common methods: whitespace splitting, BPE (Byte Pair Encoding), WordPiece, SentencePiece. Modern LLMs use subword tokenization for handling unknown words and multiple languages.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-2', text: 'What is TF-IDF?', options: ['A neural network architecture', 'Term Frequency-Inverse Document Frequency: a numerical statistic that reflects how important a word is to a document in a collection', 'A tokenization method', 'A word embedding technique'], correctAnswer: 1, explanation: 'TF-IDF = TF(t,d) × IDF(t). TF measures how often a term appears in a document. IDF = log(N/df) penalizes terms common across documents. High TF-IDF means the term is distinctive to that document.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-3', text: 'What are word embeddings (e.g., Word2Vec)?', options: ['One-hot encoded words', 'Dense vector representations of words learned from context, where semantically similar words have similar vectors', 'Binary word encodings', 'Frequency-based features'], correctAnswer: 1, explanation: 'Word embeddings map words to dense vectors (e.g., 300 dimensions) such that semantic relationships are captured geometrically. Word2Vec (CBOW/Skip-gram) learns these from co-occurrence patterns. Famous example: king - man + woman ≈ queen.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-4', text: 'What is the difference between stemming and lemmatization?', options: ['They are identical', 'Stemming crudely chops word endings (running→runn); lemmatization uses vocabulary and morphology to find the proper base form (running→run)', 'Lemmatization is faster', 'Stemming is more accurate'], correctAnswer: 1, explanation: 'Stemming applies rules to strip suffixes (Porter stemmer). It is fast but can produce non-words ("studies"→"studi"). Lemmatization uses a dictionary to find the proper base form ("studies"→"study"). Lemmatization is slower but more accurate.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-5', text: 'What is Named Entity Recognition (NER)?', options: ['Classifying documents', 'Identifying and classifying named entities (persons, organizations, locations, dates) in text', 'A text generation technique', 'Parsing sentence structure'], correctAnswer: 1, explanation: 'NER identifies spans of text that refer to entities and classifies them (PERSON, ORG, LOC, DATE, etc.). Common approaches: CRF, BiLSTM-CRF, and fine-tuned transformers. Used in information extraction, question answering, and knowledge graphs.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-6', text: 'What is the bag-of-words model?', options: ['A neural network model', 'A text representation that counts word occurrences, ignoring word order and grammar', 'A generative model', 'An embedding technique'], correctAnswer: 1, explanation: 'Bag-of-words represents text as a vector of word counts/frequencies, discarding word order. Simple but loses sequential information. Often combined with TF-IDF weighting. Works surprisingly well for document classification tasks.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-7', text: 'What is perplexity in language modeling?', options: ['Model confusion', 'A metric measuring how well a probability model predicts a sample; lower perplexity means better prediction. Equal to 2^(cross-entropy)', 'Number of parameters', 'Training time metric'], correctAnswer: 1, explanation: 'Perplexity = 2^H(p,q) where H is cross-entropy. It measures how "surprised" the model is by the test data. A perplexity of k means the model is as uncertain as choosing uniformly among k options at each step. Lower is better.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-8', text: 'What is sentiment analysis?', options: ['Grammar checking', 'Determining the emotional tone (positive, negative, neutral) of text using NLP techniques', 'Translating text between languages', 'Summarizing documents'], correctAnswer: 1, explanation: 'Sentiment analysis classifies text by emotional tone. Approaches range from lexicon-based (word polarity dictionaries) to ML (Naive Bayes, SVM with TF-IDF) to deep learning (fine-tuned BERT). Applications: product reviews, social media monitoring.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-9', text: 'What is the difference between Word2Vec CBOW and Skip-gram?', options: ['They produce the same embeddings', 'CBOW predicts a target word from its context words; Skip-gram predicts context words from a target word. Skip-gram works better for rare words.', 'CBOW is always better', 'Skip-gram is supervised'], correctAnswer: 1, explanation: 'CBOW (Continuous Bag of Words) predicts the center word from surrounding context. Skip-gram predicts surrounding words from the center word. Skip-gram performs better with small datasets and rare words; CBOW is faster with large datasets.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'nlp-basics' },
  { id: 'nlp-10', text: 'What is text preprocessing and what steps are typically involved?', options: ['Only tokenization', 'A pipeline including lowercasing, removing punctuation/stopwords, tokenization, stemming/lemmatization, and handling special characters', 'Only removing spaces', 'Converting to images'], correctAnswer: 1, explanation: 'Text preprocessing prepares raw text for NLP models. Common steps: lowercasing, removing HTML/URLs/special characters, tokenization, stopword removal, stemming/lemmatization, handling contractions. The specific steps depend on the task and model.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'nlp', lessonId: 'nlp-basics' },

  // Lesson: transformers
  { id: 'tfm-1', text: 'What is self-attention in Transformers?', options: ['A regularization technique', 'A mechanism where each position in a sequence attends to all other positions, computing attention scores using Query, Key, and Value matrices', 'Dropout for attention layers', 'A type of convolution'], correctAnswer: 1, explanation: 'Self-attention computes Attention(Q,K,V) = softmax(QK^T/√d_k)V. Each token generates Q, K, V vectors. The attention score between tokens i and j is based on Q_i · K_j. This allows every position to directly attend to every other position.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-2', text: 'What is multi-head attention?', options: ['Attention with multiple layers', 'Running self-attention multiple times in parallel with different learned projections, then concatenating the results', 'Attention across multiple sequences', 'Using multiple attention scores'], correctAnswer: 1, explanation: 'Multi-head attention runs h parallel attention "heads", each with different W_Q, W_K, W_V projection matrices. The outputs are concatenated and projected. This allows the model to attend to information from different representation subspaces simultaneously.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-3', text: 'What is positional encoding in Transformers?', options: ['Encoding the position in a database', 'Adding information about token positions since self-attention is permutation-invariant; using sinusoidal functions or learned embeddings', 'Encoding word meanings', 'A tokenization method'], correctAnswer: 1, explanation: 'Self-attention is position-agnostic. Positional encodings inject sequence order information. The original Transformer uses sinusoidal functions: PE(pos,2i) = sin(pos/10000^(2i/d)), PE(pos,2i+1) = cos(pos/10000^(2i/d)). Modern models often use learned or rotary positional embeddings.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-4', text: 'What is the difference between encoder-only, decoder-only, and encoder-decoder Transformers?', options: ['They have the same architecture', 'Encoder-only (BERT) processes full input bidirectionally; decoder-only (GPT) generates autoregressively; encoder-decoder (T5) maps input sequence to output sequence', 'Decoder-only is always best', 'Encoder-only cannot do classification'], correctAnswer: 1, explanation: 'Encoder-only (BERT): bidirectional, good for understanding tasks (classification, NER). Decoder-only (GPT): autoregressive, good for generation. Encoder-decoder (T5, BART): best for sequence-to-sequence tasks (translation, summarization).', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-5', text: 'What is masked self-attention in decoder Transformers?', options: ['Randomly masking tokens', 'Preventing each position from attending to subsequent positions by masking future tokens, ensuring autoregressive generation', 'Masking certain attention heads', 'A training-only technique'], correctAnswer: 1, explanation: 'In decoder-only models (GPT), causal/masked attention masks out future positions so token i can only attend to tokens 1..i. This maintains the autoregressive property: predictions for position i depend only on known outputs at positions before i.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-6', text: 'Why does the attention formula divide by √d_k?', options: ['To normalize probabilities', 'To prevent the dot products from growing too large with high dimensionality, which would push softmax into regions with tiny gradients', 'To reduce computation', 'It is optional'], correctAnswer: 1, explanation: 'When d_k is large, dot products can grow large in magnitude, pushing softmax output toward extreme values (near 0 or 1) where gradients are tiny. Dividing by √d_k keeps the variance of dot products at ~1, maintaining stable gradients.', difficulty: 'very_hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-7', text: 'What is BERT and how is it pre-trained?', options: ['A generative language model', 'A bidirectional encoder Transformer pre-trained using Masked Language Modeling (predicting masked tokens) and Next Sentence Prediction', 'A decoder-only model', 'A computer vision model'], correctAnswer: 1, explanation: 'BERT (Bidirectional Encoder Representations from Transformers) is pre-trained with two objectives: MLM (randomly mask 15% of tokens, predict them) and NSP (predict if two sentences are consecutive). This learns deep bidirectional representations.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-8', text: 'What is the computational complexity of self-attention with respect to sequence length?', options: ['O(n)', 'O(n²) in both time and memory, where n is the sequence length', 'O(n log n)', 'O(1)'], correctAnswer: 1, explanation: 'Self-attention computes attention between all pairs of positions, requiring O(n²) time and memory. This quadratic scaling is a key limitation for long sequences. Efficient attention variants (Linformer, FlashAttention, sparse attention) address this.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-9', text: 'What is layer normalization and why is it used in Transformers instead of batch normalization?', options: ['They are interchangeable', 'Layer norm normalizes across features for each sample (not across the batch), making it suitable for variable-length sequences and small batch sizes', 'Batch norm is better for Transformers', 'Layer norm is only for the output layer'], correctAnswer: 1, explanation: 'Layer normalization normalizes across the feature dimension for each sample independently, unlike batch norm which normalizes across the batch. This makes it independent of batch size, suitable for sequences of varying lengths, and stable during inference.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },
  { id: 'tfm-10', text: 'What is the feed-forward network (FFN) in a Transformer block?', options: ['The attention mechanism', 'A two-layer MLP applied independently to each position: FFN(x) = max(0, xW₁ + b₁)W₂ + b₂, providing non-linear transformations', 'A skip connection', 'The embedding layer'], correctAnswer: 1, explanation: 'Each Transformer block has attention followed by a position-wise FFN. The FFN applies two linear transformations with a non-linearity (ReLU or GELU) in between. The inner dimension is typically 4× the model dimension. It processes each position independently.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'transformers' },

  // Lesson: llms
  { id: 'llm-1', text: 'What is the difference between GPT and BERT architectures?', options: ['GPT is larger', 'GPT is a decoder-only autoregressive model trained to predict the next token; BERT is an encoder-only bidirectional model trained with masked language modeling', 'BERT is newer', 'They use the same training objective'], correctAnswer: 1, explanation: 'GPT uses causal (left-to-right) attention for generation tasks. BERT uses bidirectional attention for understanding tasks. GPT excels at generation; BERT excels at classification, extraction, and understanding. Modern LLMs mostly follow the GPT approach.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-2', text: 'What is Retrieval Augmented Generation (RAG)?', options: ['A training technique', 'Combining LLM generation with external knowledge retrieval: first retrieve relevant documents, then provide them as context for the LLM to generate grounded answers', 'A new model architecture', 'A fine-tuning method'], correctAnswer: 1, explanation: 'RAG addresses LLM hallucination and knowledge cutoff by retrieving relevant documents (using vector similarity search) and providing them as context. The LLM generates answers grounded in the retrieved information, improving factual accuracy.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-3', text: 'What is fine-tuning an LLM and when would you use it vs. RAG?', options: ['Fine-tuning and RAG are the same', 'Fine-tuning updates model weights on task-specific data for behavior/style changes; RAG is better for adding new knowledge without retraining. Use fine-tuning for format/style, RAG for knowledge.', 'Fine-tuning is always better', 'RAG requires more compute'], correctAnswer: 1, explanation: 'Fine-tuning: modifies model weights, good for learning new formats/styles/behaviors, requires GPU compute. RAG: keeps model frozen, retrieves external knowledge at inference, good for adding/updating knowledge. Often combined for best results.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-4', text: 'What is prompt engineering?', options: ['Building prompts for manufacturing', 'Carefully crafting input text to guide LLM behavior, including techniques like few-shot examples, chain-of-thought, and system prompts', 'A programming language', 'Fine-tuning model weights'], correctAnswer: 1, explanation: 'Prompt engineering designs effective prompts to elicit desired LLM outputs. Techniques: zero-shot (just instructions), few-shot (include examples), chain-of-thought (encourage step-by-step reasoning), system prompts (set behavior/persona).', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-5', text: 'What is RLHF (Reinforcement Learning from Human Feedback)?', options: ['Training with reinforcement learning on games', 'A technique that trains a reward model from human preferences, then uses it to fine-tune the LLM via PPO to align with human values and preferences', 'Human-guided data labeling', 'A supervised learning method'], correctAnswer: 1, explanation: 'RLHF: (1) Collect human preference data (rank model outputs), (2) Train a reward model on these preferences, (3) Use PPO to optimize the LLM against the reward model. This aligns LLMs with human intentions and safety preferences. Used in ChatGPT, Claude.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-6', text: 'What is LoRA (Low-Rank Adaptation)?', options: ['A new LLM architecture', 'A parameter-efficient fine-tuning method that freezes pre-trained weights and adds trainable low-rank decomposition matrices to attention layers', 'A data augmentation technique', 'A prompt engineering method'], correctAnswer: 1, explanation: 'LoRA adds trainable low-rank matrices (A and B where W\' = W + BA) to frozen pre-trained weights. This reduces trainable parameters by 100-1000× while achieving comparable performance to full fine-tuning. Popular for adapting LLMs efficiently.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-7', text: 'What is the "temperature" parameter in LLM generation?', options: ['GPU temperature', 'A parameter that controls randomness in token sampling: higher temperature produces more diverse/creative outputs, lower temperature produces more focused/deterministic outputs', 'Training speed parameter', 'Model size parameter'], correctAnswer: 1, explanation: 'Temperature (T) scales logits before softmax: softmax(logits/T). T=0: greedy (most likely token). T<1: sharper distribution, less random. T>1: flatter distribution, more random. It controls the creativity vs. determinism tradeoff in generation.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-8', text: 'What are AI agents and how do they use LLMs?', options: ['Chatbots that answer questions', 'Autonomous systems that use LLMs as reasoning engines, combined with tools (search, code execution, APIs) to complete complex multi-step tasks', 'Pre-trained models', 'Data pipelines'], correctAnswer: 1, explanation: 'AI agents use LLMs to reason, plan, and take actions. They combine LLMs with tool use (web search, calculators, code interpreters, APIs), memory (conversation history, vector stores), and planning (task decomposition, reflection). Examples: AutoGPT, LangChain agents.', difficulty: 'medium', roles: ['ai_engineer', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-9', text: 'What is quantization in the context of LLMs?', options: ['Counting model parameters', 'Reducing model weight precision (e.g., from FP32 to INT8 or INT4) to decrease memory usage and increase inference speed with minimal quality loss', 'A training technique', 'Adding more parameters'], correctAnswer: 1, explanation: 'Quantization converts weights from higher precision (FP32/FP16) to lower precision (INT8, INT4). GPTQ, GGUF, and AWQ are popular methods. 4-bit quantization can reduce memory by ~4× with 1-3% quality loss, enabling running large models on consumer hardware.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'nlp', lessonId: 'llms' },
  { id: 'llm-10', text: 'What is the context window limitation of LLMs and how is it being addressed?', options: ['LLMs have no limitations', 'LLMs can only process a fixed number of tokens at once; addressed through techniques like RoPE scaling, sparse attention, sliding window attention, and retrieval augmentation', 'Context window only affects training', 'Just use a bigger model'], correctAnswer: 1, explanation: 'Transformer context windows are limited (originally 512-2048 tokens, now up to 100K+). Limitations are addressed by: positional encoding extensions (RoPE scaling), efficient attention (FlashAttention), sliding window (Mistral), and RAG for external knowledge.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'nlp', lessonId: 'llms' },

  // ====== UNIT: computer-vision ======
  // Lesson: cv-fundamentals
  { id: 'cv-1', text: 'What is image classification vs. object detection vs. image segmentation?', options: ['They are the same task', 'Classification assigns a label to the whole image; detection finds and localizes objects with bounding boxes; segmentation classifies each pixel', 'Detection is a special case of classification', 'Segmentation only works with binary images'], correctAnswer: 1, explanation: 'Classification: "this image contains a cat". Detection: "there is a cat at [x,y,w,h]". Semantic segmentation: each pixel classified (cat/background). Instance segmentation: each pixel classified and individual objects separated.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-2', text: 'What is the difference between semantic segmentation and instance segmentation?', options: ['They are identical', 'Semantic segmentation classifies each pixel by class but does not distinguish between instances; instance segmentation also separates individual object instances', 'Instance segmentation is simpler', 'Semantic segmentation works per-object'], correctAnswer: 1, explanation: 'Semantic segmentation labels every pixel with a class (all "person" pixels get the same label). Instance segmentation additionally separates individual instances (person 1, person 2). Panoptic segmentation combines both for stuff and things.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-3', text: 'What is IoU (Intersection over Union) in object detection?', options: ['A loss function', 'The ratio of the area of overlap between predicted and ground truth bounding boxes to the area of their union; used to evaluate detection quality', 'A training metric only', 'The number of true positives'], correctAnswer: 1, explanation: 'IoU = Area(Pred ∩ GT) / Area(Pred ∪ GT). It ranges from 0 (no overlap) to 1 (perfect overlap). Typically, IoU > 0.5 is considered a correct detection. mAP (mean Average Precision) is computed at different IoU thresholds.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-4', text: 'What is Non-Maximum Suppression (NMS)?', options: ['Removing maximum values from images', 'A post-processing step in object detection that removes redundant overlapping bounding boxes, keeping only the highest-confidence detection per object', 'A training technique', 'A type of pooling'], correctAnswer: 1, explanation: 'NMS removes duplicate detections: (1) sort boxes by confidence, (2) select the highest-confidence box, (3) remove all boxes with IoU > threshold with it, (4) repeat. This ensures one detection per object.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-5', text: 'What are anchor boxes in object detection models?', options: ['Boxes that anchor the image', 'Pre-defined bounding boxes of various sizes and aspect ratios that serve as reference proposals; the model predicts offsets from these anchors', 'A type of padding', 'User-drawn bounding boxes'], correctAnswer: 1, explanation: 'Anchor boxes are predefined reference boxes at each spatial location. The model predicts: (1) whether each anchor contains an object, and (2) offsets to refine the anchor into the actual bounding box. Used in Faster R-CNN, SSD, YOLOv2+.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-6', text: 'What is the difference between one-stage and two-stage object detectors?', options: ['Number of training stages', 'Two-stage (Faster R-CNN) first proposes regions then classifies them; one-stage (YOLO, SSD) directly predicts boxes and classes in a single pass, trading some accuracy for speed', 'One-stage is always more accurate', 'Two-stage is always faster'], correctAnswer: 1, explanation: 'Two-stage: Region proposal (RPN) → ROI classification/regression (Faster R-CNN). Generally more accurate. One-stage: directly predict boxes + classes from feature maps (YOLO, SSD). Much faster, approaching two-stage accuracy with modern architectures.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-7', text: 'What is a Vision Transformer (ViT)?', options: ['A CNN with attention', 'A model that applies the Transformer architecture directly to image patches: split image into patches, embed them, and process with standard Transformer encoder', 'A specialized GPU for vision', 'A GAN for images'], correctAnswer: 1, explanation: 'ViT splits an image into fixed-size patches (e.g., 16×16), linearly embeds each patch, adds positional embeddings, and processes them with a standard Transformer encoder. With sufficient data, ViT achieves state-of-the-art image classification, rivaling CNNs.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-8', text: 'What is a Generative Adversarial Network (GAN)?', options: ['A classifier', 'Two neural networks (generator and discriminator) trained adversarially: the generator creates fake samples, the discriminator distinguishes real from fake', 'A type of autoencoder', 'A supervised model'], correctAnswer: 1, explanation: 'GANs pit a Generator (creates fake data) against a Discriminator (classifies real vs fake). They are trained in a minimax game until the generator produces realistic samples. Used for image generation, style transfer, super-resolution.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-9', text: 'What is a diffusion model?', options: ['A model for fluid dynamics', 'A generative model that gradually adds noise to data (forward process) and then learns to reverse this process (denoising) to generate new samples', 'A CNN variant', 'A recommendation model'], correctAnswer: 1, explanation: 'Diffusion models (DDPM, Stable Diffusion) work in two phases: forward process gradually adds Gaussian noise until data becomes noise; reverse process learns to denoise step by step. They produce high-quality images and have largely replaced GANs for image generation.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },
  { id: 'cv-10', text: 'What is CLIP (Contrastive Language-Image Pre-training)?', options: ['An image compression method', 'A model that learns to associate images and text descriptions by training on image-text pairs with contrastive learning, enabling zero-shot image classification', 'A video model', 'A data augmentation technique'], correctAnswer: 1, explanation: 'CLIP (OpenAI) trains an image encoder and text encoder jointly using contrastive learning on 400M image-text pairs. Given an image, it can match it to any text description, enabling zero-shot classification without task-specific training.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'cv-fundamentals' },

  // Lesson: detection-segmentation
  { id: 'ds-1', text: 'How does YOLO (You Only Look Once) work?', options: ['It processes the image multiple times', 'It divides the image into a grid, each cell predicts bounding boxes and class probabilities simultaneously in a single forward pass', 'It uses region proposals', 'It only detects one object'], correctAnswer: 1, explanation: 'YOLO divides the image into an S×S grid. Each cell predicts B bounding boxes (with confidence) and C class probabilities. This single-pass approach makes YOLO extremely fast (real-time detection) while maintaining good accuracy.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-2', text: 'What is Feature Pyramid Network (FPN)?', options: ['A deep network with many layers', 'A multi-scale feature extraction architecture that combines low-resolution semantically strong features with high-resolution spatially detailed features through top-down pathways', 'A pyramid-shaped neural network', 'A dimensionality reduction technique'], correctAnswer: 1, explanation: 'FPN creates a feature pyramid by combining bottom-up (forward pass) and top-down (upsampled) feature maps with lateral connections. This provides strong multi-scale features at all levels, crucial for detecting objects of different sizes.', difficulty: 'very_hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-3', text: 'What is U-Net and why is it popular for segmentation?', options: ['A network shaped like the letter U', 'An encoder-decoder architecture with skip connections between corresponding layers that preserves spatial detail, making it excellent for medical and semantic segmentation', 'A type of GAN', 'Only works for CT scans'], correctAnswer: 1, explanation: 'U-Net has an encoder (downsampling) and decoder (upsampling) path connected by skip connections that pass fine-grained details from encoder to decoder. This architecture preserves spatial information crucial for pixel-precise segmentation, especially with limited data.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-4', text: 'What is mAP (mean Average Precision) in object detection?', options: ['Mean accuracy percentage', 'The mean of Average Precision across all object classes, where AP is the area under the precision-recall curve at different IoU thresholds', 'Maximum average precision', 'A loss function'], correctAnswer: 1, explanation: 'AP computes the area under the precision-recall curve for one class. mAP averages AP across all classes. COCO mAP averages over IoU thresholds from 0.50 to 0.95 (step 0.05). mAP@0.50 uses a single IoU threshold of 0.50.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-5', text: 'What is ROI Pooling in Faster R-CNN?', options: ['Pooling the region of interest from a vacation', 'Extracting fixed-size feature maps from arbitrary-sized region proposals by dividing each ROI into a fixed grid and max-pooling each cell', 'A data augmentation technique', 'A normalization method'], correctAnswer: 1, explanation: 'ROI Pooling takes a variable-sized region proposal from the feature map and produces a fixed-size output (e.g., 7×7). It divides the ROI into a grid and applies max pooling to each cell. ROI Align (improved version) uses bilinear interpolation to avoid quantization.', difficulty: 'very_hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-6', text: 'What is the difference between Mask R-CNN and Faster R-CNN?', options: ['They are identical', 'Mask R-CNN extends Faster R-CNN by adding a parallel branch that predicts a segmentation mask for each detected object, enabling instance segmentation', 'Mask R-CNN is faster', 'Faster R-CNN does segmentation too'], correctAnswer: 1, explanation: 'Mask R-CNN adds a mask prediction branch alongside the existing bounding box and classification branches of Faster R-CNN. For each ROI, it predicts a binary mask, enabling instance segmentation. Uses ROI Align instead of ROI Pooling.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-7', text: 'What are the challenges of real-time object detection?', options: ['Only accuracy matters', 'Balancing accuracy with inference speed, handling varying object scales, dealing with occlusions, and optimizing for edge deployment with limited compute', 'Real-time detection is trivial', 'Only works on GPUs'], correctAnswer: 1, explanation: 'Challenges include: latency constraints (<33ms for 30fps), multi-scale detection, small object detection, occlusion handling, class imbalance, model compression for edge devices. Modern approaches: YOLO variants, quantization, pruning, TensorRT optimization.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-8', text: 'What is optical flow in computer vision?', options: ['Light transmission through lenses', 'The pattern of apparent motion of objects between consecutive frames in a video, represented as a 2D vector field', 'A type of image filter', 'Camera calibration technique'], correctAnswer: 1, explanation: 'Optical flow estimates per-pixel motion between frames. Each pixel gets a 2D vector (dx, dy) indicating its apparent motion. Methods: Lucas-Kanade (sparse), Farneback (dense), FlowNet/RAFT (deep learning). Used in video analysis, action recognition, autonomous driving.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-9', text: 'What is image augmentation specifically useful for in detection and segmentation tasks?', options: ['Only for classification', 'It helps the model generalize to different scales, orientations, lighting conditions, and occlusions; includes random cropping, mosaic augmentation, and photometric distortion', 'It reduces training time', 'It is not needed for detection'], correctAnswer: 1, explanation: 'Detection/segmentation augmentations must transform both images AND annotations (boxes, masks). Techniques: random crop/resize (multi-scale), horizontal flip, mosaic (YOLO), copy-paste (segmentation), color jitter, cutout. These dramatically improve robustness.', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },
  { id: 'ds-10', text: 'What is the SAM (Segment Anything Model) and why is it significant?', options: ['A simple segmentation model', 'A foundation model for image segmentation that can segment any object in any image with various prompts (points, boxes, text), trained on 11M images and 1B masks', 'A medical imaging tool only', 'A GAN for segmentation'], correctAnswer: 1, explanation: 'SAM (Meta AI) is a promptable segmentation model. Given an image and a prompt (point, box, or text), it segments the indicated object. Trained on the SA-1B dataset (11M images, 1.1B masks), it generalizes to new objects/images without additional training.', difficulty: 'hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'computer-vision', lessonId: 'detection-segmentation' },

  // ====== UNIT: feature-engineering ======
  { id: 'fe-1', text: 'How should you handle missing values in a dataset?', options: ['Always delete rows with missing values', 'Depends on the context: imputation (mean/median/mode/KNN), deletion (if random and small fraction), or using models that handle missing values natively (XGBoost)', 'Always fill with zeros', 'Ignore them'], correctAnswer: 1, explanation: 'Strategy depends on: missing mechanism (MCAR, MAR, MNAR), fraction missing, and model choice. Options: mean/median/mode imputation, KNN imputation, MICE (multivariate), deletion (if MCAR and < 5%), indicator variables, or using tree-based models that handle NaN.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-2', text: 'What is the difference between normalization and standardization?', options: ['They are the same', 'Normalization scales features to [0,1]; standardization transforms to zero mean and unit variance (z-score). Standardization is preferred when features have different scales.', 'Normalization is always better', 'Standardization only works for normal distributions'], correctAnswer: 1, explanation: 'Normalization (Min-Max): x\' = (x - min)/(max - min), scales to [0,1]. Standardization (Z-score): x\' = (x - μ)/σ, centers at 0 with σ=1. Standardization is robust to outliers and preferred for most ML algorithms. Normalization is useful for bounded features.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-3', text: 'How do you handle categorical variables for machine learning?', options: ['Always use integers', 'Encoding methods include: one-hot encoding, label encoding, target encoding, binary encoding, or embeddings, depending on cardinality and model type', 'Only tree models can handle categories', 'Convert to strings'], correctAnswer: 1, explanation: 'Low cardinality: one-hot encoding (creates binary columns). Ordinal: label encoding. High cardinality: target encoding, frequency encoding, or learned embeddings. Tree models can use label encoding directly. One-hot can cause dimensionality issues with high cardinality.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-4', text: 'What is data leakage and how can it be prevented?', options: ['Data being stolen', 'When information from the test set or future data inadvertently influences model training, producing overly optimistic performance estimates', 'Memory leaks in code', 'Data loss during transfer'], correctAnswer: 1, explanation: 'Data leakage occurs when training uses information not available at prediction time. Examples: using future data, fitting scalers on test data, target leakage (feature derived from target). Prevention: strict train/test split, pipeline-based preprocessing, temporal validation.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-5', text: 'How do you detect and handle outliers?', options: ['Always remove them', 'Detection: IQR method, z-score (>3σ), isolation forest, DBSCAN. Handling: remove, cap/floor (winsorize), transform (log), or use robust models depending on whether outliers are errors or valid extreme values', 'Outliers never affect models', 'Only box plots can detect outliers'], correctAnswer: 1, explanation: 'Detection methods: statistical (z-score, IQR), visual (box plots, scatter), model-based (isolation forest, LOF). Handling depends on cause: errors → remove, valid extremes → transform (log, winsorize) or use robust models. Always investigate before removing.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-6', text: 'What is PCA (Principal Component Analysis)?', options: ['A classification algorithm', 'A dimensionality reduction technique that finds orthogonal directions of maximum variance in data, projecting data onto these principal components', 'A clustering method', 'A regularization technique'], correctAnswer: 1, explanation: 'PCA finds the directions (eigenvectors of the covariance matrix) along which data varies most. Projecting onto the top k components reduces dimensionality while retaining maximum variance. Useful for visualization, noise reduction, and handling multicollinearity.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-7', text: 'What is the difference between filter, wrapper, and embedded feature selection methods?', options: ['They all use the same approach', 'Filter methods use statistical tests independent of model; wrapper methods evaluate subsets using a model; embedded methods perform selection during training (e.g., Lasso)', 'Filter methods are always best', 'Only embedded methods work'], correctAnswer: 1, explanation: 'Filter: statistical measures (correlation, chi-squared, mutual information) independent of model. Wrapper: evaluate feature subsets with a model (forward/backward selection, RFE). Embedded: selection during training (Lasso, tree importance). Trade-off: speed vs. accuracy.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-8', text: 'What is target encoding and when can it be problematic?', options: ['Encoding the target as one-hot', 'Replacing a categorical value with the mean target value for that category; can cause data leakage and overfitting if not done with proper regularization', 'The same as label encoding', 'A type of feature scaling'], correctAnswer: 1, explanation: 'Target encoding replaces each category with the mean of the target variable for that category. Risk: data leakage (using target info in features) and overfitting to rare categories. Solutions: smoothing/regularization, cross-validation-based encoding, adding noise.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-9', text: 'When should you apply log transformation to features?', options: ['Always', 'When data is right-skewed, has exponential growth patterns, or when the relationship with the target is multiplicative rather than additive', 'Never for ML models', 'Only for the target variable'], correctAnswer: 1, explanation: 'Log transformation is useful for: right-skewed distributions (making them more normal), stabilizing variance, handling multiplicative relationships, and reducing the impact of extreme values. Common for income, prices, counts. Use log(1+x) to handle zeros.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'feature-engineering', lessonId: 'data-preprocessing' },
  { id: 'fe-10', text: 'What is feature crossing and when is it useful?', options: ['Crossing out features', 'Creating new features by combining existing ones (multiplication, concatenation) to capture interaction effects that individual features cannot represent', 'A type of cross-validation', 'Swapping features between datasets'], correctAnswer: 1, explanation: 'Feature crosses create new features from combinations of existing ones. Example: latitude × longitude to capture location. price × quantity for revenue. Linear models especially benefit as they cannot learn interactions automatically. Tree models learn interactions natively.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },

  // feature-techniques lesson
  { id: 'ft-1', text: 'What is t-SNE and how does it differ from PCA?', options: ['They do the same thing', 't-SNE is a nonlinear technique that preserves local structure for visualization (typically 2D/3D); PCA is linear and preserves global variance. t-SNE is better for cluster visualization.', 't-SNE is always better', 'PCA is only for images'], correctAnswer: 1, explanation: 't-SNE (t-distributed Stochastic Neighbor Embedding) preserves local neighborhood structure, making it excellent for visualizing clusters. PCA preserves global variance and is deterministic. t-SNE is non-deterministic, slower, and mainly for visualization (not preprocessing).', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-2', text: 'What are polynomial features and when should you use them?', options: ['Features that are polynomials', 'Creating new features by computing polynomial combinations (x², x₁x₂) of existing features, useful for capturing nonlinear relationships in linear models', 'Only for regression tasks', 'They always improve performance'], correctAnswer: 1, explanation: 'Polynomial features generate all polynomial combinations up to degree d. With 2 features and degree 2: [x₁, x₂, x₁², x₁x₂, x₂²]. Useful for linear models to capture nonlinearity. Warning: feature explosion with high degree or many features; regularization is essential.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-3', text: 'What is UMAP and how does it compare to t-SNE?', options: ['A mapping library', 'UMAP (Uniform Manifold Approximation) is a dimensionality reduction method that is faster than t-SNE, preserves more global structure, and can be used for non-visualization tasks', 'UMAP only works in 3D', 'They are identical'], correctAnswer: 1, explanation: 'UMAP is based on Riemannian geometry and algebraic topology. Compared to t-SNE: faster (especially for large datasets), better preserves global structure, supports arbitrary output dimensions, and can be used as preprocessing (not just visualization).', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-4', text: 'How do you create features from datetime data?', options: ['Use the raw timestamp', 'Extract components (hour, day of week, month, year), create cyclical features (sin/cos encoding), compute time differences, and identify patterns (weekday/weekend, holiday)', 'Convert to strings', 'Only use the date'], correctAnswer: 1, explanation: 'Datetime features: hour/day/month/year extraction, day of week, is_weekend, is_holiday, time since event, cyclical encoding (sin/cos for hour/month to capture cyclical nature), lag features, rolling statistics for time-based patterns.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-5', text: 'What is a feature store?', options: ['A database for storing raw data', 'A centralized repository for storing, managing, and serving ML features, ensuring consistency between training and serving and enabling feature reuse across teams', 'A file system', 'A model registry'], correctAnswer: 1, explanation: 'Feature stores (Feast, Tecton, Hopsworks) provide: centralized feature definitions, offline (batch) and online (real-time) serving, feature versioning, point-in-time correctness, feature sharing across teams, and training-serving consistency.', difficulty: 'hard', roles: ['ml_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-6', text: 'What is binning/bucketing and when is it useful?', options: ['Deleting data', 'Converting continuous features into discrete bins/categories (e.g., age ranges), useful for handling nonlinear relationships, reducing noise, and handling outliers', 'A sorting algorithm', 'Only for visualization'], correctAnswer: 1, explanation: 'Binning converts continuous values to discrete bins. Methods: equal-width, equal-frequency (quantile), custom domain-based. Benefits: handles nonlinearity for linear models, reduces noise, mitigates outlier effects. Drawback: loses information within bins.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-7', text: 'What is the difference between label encoding and ordinal encoding?', options: ['They are the same thing', 'Label encoding assigns arbitrary integers to categories (no order); ordinal encoding assigns integers that respect a natural order (e.g., low=1, medium=2, high=3)', 'Ordinal encoding only works with numbers', 'Label encoding preserves order'], correctAnswer: 1, explanation: 'Label encoding assigns arbitrary integers (cat=0, dog=1, bird=2) with no implied order. Ordinal encoding assigns integers that reflect natural ordering (cold=0 < warm=1 < hot=2). Using label encoding for tree models is fine; for linear models, ordinal relationships matter.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-8', text: 'What is Recursive Feature Elimination (RFE)?', options: ['Deleting all features', 'A wrapper method that repeatedly trains a model, removes the least important feature(s), and repeats until the desired number of features is reached', 'A dimensionality reduction method', 'A type of cross-validation'], correctAnswer: 1, explanation: 'RFE: (1) Train model on all features, (2) Rank features by importance, (3) Remove the least important feature(s), (4) Repeat. RFECV adds cross-validation to find the optimal number of features. Works with any model that provides feature importances.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },
  { id: 'ft-9', text: 'What is the Variance Inflation Factor (VIF)?', options: ['A measure of feature variance', 'A metric that quantifies how much the variance of a regression coefficient is inflated due to multicollinearity; VIF > 5-10 indicates problematic collinearity', 'The inflation rate of model predictions', 'A type of regularization'], correctAnswer: 1, explanation: 'VIF measures multicollinearity: VIF_j = 1/(1-R²_j), where R²_j is from regressing feature j on all other features. VIF=1 means no collinearity, VIF>5-10 indicates problematic collinearity. High VIF features should be removed or combined.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'feature-engineering', lessonId: 'feature-techniques' },

  // ====== UNIT: model-evaluation ======
  { id: 'me-1', text: 'What is the confusion matrix?', options: ['A matrix that causes confusion', 'A table showing True Positives, False Positives, True Negatives, and False Negatives for a classifier, from which many metrics can be derived', 'A correlation matrix', 'A feature matrix'], correctAnswer: 1, explanation: 'The confusion matrix for binary classification has 4 cells: TP (predicted positive, actually positive), FP (predicted positive, actually negative), TN (predicted negative, actually negative), FN (predicted negative, actually positive). It is the basis for precision, recall, F1.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-2', text: 'What is the difference between precision and recall?', options: ['They are the same', 'Precision = TP/(TP+FP) measures how many positive predictions are correct; Recall = TP/(TP+FN) measures how many actual positives are found', 'Precision is always more important', 'Recall is TP/TN'], correctAnswer: 1, explanation: 'Precision: of all positive predictions, how many are correct? (low FP). Recall: of all actual positives, how many are found? (low FN). Trade-off: higher threshold → higher precision, lower recall. Use case determines priority (spam: precision, cancer: recall).', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-3', text: 'What is the F1 score and when should you use it?', options: ['The first feature importance score', 'The harmonic mean of precision and recall: F1 = 2×(P×R)/(P+R), useful when you need a balance between precision and recall, especially with imbalanced classes', 'The arithmetic mean of P and R', 'Only for multi-class problems'], correctAnswer: 1, explanation: 'F1 = 2PR/(P+R) is the harmonic mean of precision and recall (harmonic mean penalizes extreme imbalances). Use F1 when: classes are imbalanced, both FP and FN matter, you need a single metric. Fβ allows weighting: β>1 favors recall, β<1 favors precision.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-4', text: 'What is AUC-ROC?', options: ['A medical test', 'Area Under the Receiver Operating Characteristic curve, which plots TPR vs FPR at various thresholds; measures the model\'s ability to discriminate between classes regardless of threshold', 'A type of regularization', 'Accuracy Under Constraints'], correctAnswer: 1, explanation: 'ROC curve plots True Positive Rate (recall) vs False Positive Rate (FP/N) at all thresholds. AUC-ROC = area under this curve. AUC = 0.5: random, AUC = 1.0: perfect. It is threshold-independent and robust to class imbalance.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-5', text: 'When should you use AUC-PR (Precision-Recall) instead of AUC-ROC?', options: ['They are interchangeable', 'When classes are heavily imbalanced, AUC-PR is more informative because AUC-ROC can be misleadingly optimistic when negatives dominate', 'AUC-ROC is always better', 'AUC-PR is only for multi-class'], correctAnswer: 1, explanation: 'With severe class imbalance (e.g., 1% positive), AUC-ROC can be high even for poor models because TN dominates. AUC-PR focuses on the minority (positive) class, giving a more realistic picture. Use AUC-PR when the positive class is rare and important.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-6', text: 'What is log loss (cross-entropy loss)?', options: ['The logarithm of the loss', 'A loss function that penalizes confident wrong predictions heavily: -Σ[y×log(p) + (1-y)×log(1-p)], measuring the quality of probabilistic predictions', 'Only for regression', 'The same as MSE'], correctAnswer: 1, explanation: 'Log loss = -1/N Σ[yᵢlog(pᵢ) + (1-yᵢ)log(1-pᵢ)]. It heavily penalizes confident wrong predictions (predicting 0.99 when actual is 0). Lower is better. It measures how well predicted probabilities match actual labels. Used for logistic regression, neural networks.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-7', text: 'What is calibration in the context of classification models?', options: ['Adjusting hardware settings', 'How well the predicted probabilities match the true likelihood of outcomes; a well-calibrated model predicting 70% probability should be correct ~70% of the time', 'Setting hyperparameters', 'Adjusting class weights'], correctAnswer: 1, explanation: 'A calibrated model means P(correct|predicted p) ≈ p. Many models (SVM, random forests, boosted trees) produce uncalibrated probabilities. Platt scaling (sigmoid) or isotonic regression can calibrate them. Reliability diagrams visualize calibration.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-8', text: 'What is the Matthews Correlation Coefficient (MCC)?', options: ['A simple correlation measure', 'A balanced metric for binary classification that accounts for all four confusion matrix values, ranging from -1 (total disagreement) to +1 (perfect prediction)', 'Only for regression', 'The same as accuracy'], correctAnswer: 1, explanation: 'MCC = (TP×TN - FP×FN) / √((TP+FP)(TP+FN)(TN+FP)(TN+FN)). Unlike accuracy, it is balanced even for imbalanced classes. MCC = 1: perfect, 0: random, -1: total disagreement. Often considered the most informative single metric for binary classification.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-9', text: 'What is stratified K-fold cross-validation?', options: ['Standard K-fold with larger K', 'K-fold cross-validation where each fold maintains the same proportion of each class as the full dataset, important for imbalanced classification', 'K-fold for stratified data only', 'Using different models per fold'], correctAnswer: 1, explanation: 'Stratified K-fold ensures each fold has approximately the same class distribution as the entire dataset. This is crucial for imbalanced classification where random splits might create folds with very few minority class samples.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },
  { id: 'me-10', text: 'What is the BLEU score used for?', options: ['Rating text quality subjectively', 'Evaluating machine translation quality by comparing n-gram overlap between generated and reference translations, with a brevity penalty', 'A classification metric', 'Measuring model speed'], correctAnswer: 1, explanation: 'BLEU (Bilingual Evaluation Understudy) computes precision of n-grams (1-gram to 4-gram) between generated and reference text, with a brevity penalty for short outputs. Score ranges from 0 to 1. Widely used but has limitations (ignores recall, meaning).', difficulty: 'medium', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'metrics' },

  // Lesson: validation-strategies
  { id: 'vs-1', text: 'What is time-series cross-validation?', options: ['Standard K-fold on time series', 'A validation strategy that respects temporal order: training on past data and validating on future data, using expanding or sliding window approaches', 'Shuffling time series data', 'Using the last 10% as test'], correctAnswer: 1, explanation: 'Standard K-fold is invalid for time series (data leakage from future). Time series CV uses expanding windows (train on 1..t, validate on t+1..t+k) or sliding windows. This respects the temporal nature of the data.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-2', text: 'What is the difference between validation set and test set?', options: ['They are the same', 'Validation set is used during development for hyperparameter tuning; test set is held out and only used once for final evaluation', 'Test set is larger', 'Validation set is used after training only'], correctAnswer: 1, explanation: 'Validation set: used repeatedly during development to tune hyperparameters, compare models, and make design decisions. Test set: used ONCE at the end for final, unbiased performance estimation. Repeatedly using the test set causes information leakage.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-3', text: 'What is hyperparameter tuning and what methods exist?', options: ['Adjusting model weights', 'Searching for optimal hyperparameters using methods like grid search, random search, Bayesian optimization, or Hyperband', 'Training the model longer', 'Feature selection'], correctAnswer: 1, explanation: 'Hyperparameter tuning finds optimal settings (learning rate, depth, regularization). Methods: Grid search (exhaustive but expensive), Random search (surprisingly effective), Bayesian optimization (Optuna, models the objective function), Hyperband (early stopping of poor configs).', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-4', text: 'Why is random search often better than grid search for hyperparameter tuning?', options: ['Random search is exhaustive', 'Random search explores more unique values of each hyperparameter and is more efficient when some hyperparameters matter more than others', 'Grid search is always better', 'Random search uses fewer resources'], correctAnswer: 1, explanation: 'Grid search wastes evaluations on unimportant parameter combinations. If only 2 of 5 hyperparameters matter significantly, random search explores more unique values of those important parameters per evaluation. It achieves comparable results with fewer iterations.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-5', text: 'What is nested cross-validation?', options: ['Cross-validation inside cross-validation', 'An outer CV loop for model evaluation and an inner CV loop for hyperparameter tuning, providing unbiased performance estimates for the entire model selection process', 'K-fold with K>10', 'Training on the full dataset'], correctAnswer: 1, explanation: 'Nested CV has two loops: outer loop splits data for evaluation, inner loop (within each outer fold) tunes hyperparameters. This prevents the selection bias from tuning hyperparameters on the same data used for evaluation. Gives unbiased generalization estimate.', difficulty: 'very_hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-6', text: 'How do you detect overfitting?', options: ['Looking at training accuracy only', 'Comparing training and validation performance: large gap (high train, low validation) indicates overfitting; monitor learning curves over epochs/complexity', 'Overfitting cannot be detected', 'Only by testing on new data'], correctAnswer: 1, explanation: 'Overfitting signs: training loss decreasing but validation loss increasing, large gap between train and validation metrics, model complexity too high for data size. Use learning curves (performance vs. training size/epochs) to diagnose and early stopping to prevent.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-7', text: 'What is group K-fold cross-validation?', options: ['K-fold for groups of features', 'A CV strategy that ensures samples from the same group (e.g., same patient, user) never appear in both training and validation, preventing data leakage', 'Grouping similar models together', 'K-fold with grouped features'], correctAnswer: 1, explanation: 'Group K-fold ensures group-level separation: all samples from one group go to the same fold. This prevents leakage when samples within a group are correlated (e.g., multiple images from same patient, multiple transactions from same user).', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-8', text: 'What is Bayesian Optimization for hyperparameter tuning?', options: ['Using Bayes theorem for prediction', 'An intelligent search that builds a probabilistic model (Gaussian Process) of the objective function and uses an acquisition function to decide which hyperparameters to try next', 'Bayesian updating of model weights', 'A random search variant'], correctAnswer: 1, explanation: 'Bayesian optimization: (1) builds a surrogate model (GP, TPE) of the objective function, (2) uses an acquisition function (Expected Improvement, UCB) to balance exploration vs exploitation, (3) evaluates the most promising point, (4) updates the model. Much more sample-efficient than grid/random search.', difficulty: 'very_hard', roles: ['ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-9', text: 'What is the bias-variance decomposition of expected error?', options: ['Error = Bias + Variance', 'Expected Error = Bias² + Variance + Irreducible Error; this decomposition helps diagnose model problems and guide complexity decisions', 'Error = 1 - Accuracy', 'Only applies to regression'], correctAnswer: 1, explanation: 'E[(y - ŷ)²] = Bias²(ŷ) + Var(ŷ) + σ² (noise). High bias (underfitting): model too simple, high training error. High variance (overfitting): model too complex, high gap between train/test. σ² is irreducible noise in the data.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },
  { id: 'vs-10', text: 'What are learning curves and how do you interpret them?', options: ['Curves that show learning rate', 'Plots of model performance vs. training set size or training epochs, used to diagnose underfitting, overfitting, and whether more data would help', 'Only useful for deep learning', 'Plots of accuracy over time'], correctAnswer: 1, explanation: 'Learning curves plot performance against training size or epochs. Underfitting: both train and validation scores are low. Overfitting: train score is high but validation score is low (gap). More data helps if validation is still improving but train-val gap exists.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'model-evaluation', lessonId: 'validation-strategies' },

  // ====== UNIT: sql-data ======
  { id: 'sql-1', text: 'What is the difference between INNER JOIN and LEFT JOIN?', options: ['They return the same results', 'INNER JOIN returns only matching rows from both tables; LEFT JOIN returns all rows from the left table and matching rows from the right (NULL for non-matches)', 'LEFT JOIN is faster', 'INNER JOIN returns all rows'], correctAnswer: 1, explanation: 'INNER JOIN: only rows with matches in both tables. LEFT JOIN: all rows from left table + matching rows from right (NULL if no match). RIGHT JOIN: opposite. FULL OUTER JOIN: all rows from both tables with NULLs where no match.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-2', text: 'What is the difference between WHERE and HAVING?', options: ['They are identical', 'WHERE filters individual rows before grouping; HAVING filters groups after GROUP BY aggregation', 'HAVING is applied before WHERE', 'WHERE works with aggregates'], correctAnswer: 1, explanation: 'WHERE filters rows before aggregation (cannot use aggregate functions). HAVING filters groups after GROUP BY (can use aggregate functions). Example: WHERE salary > 50000 vs HAVING AVG(salary) > 50000.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-3', text: 'What is a window function in SQL?', options: ['A function for UI windows', 'A function that performs calculations across a set of rows related to the current row without collapsing them, using OVER() clause with PARTITION BY and ORDER BY', 'The same as GROUP BY', 'A stored procedure'], correctAnswer: 1, explanation: 'Window functions compute values across related rows without grouping. Syntax: func() OVER (PARTITION BY col ORDER BY col). Examples: ROW_NUMBER(), RANK(), LAG(), LEAD(), SUM() OVER(), running averages. They are extremely powerful for analytics.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-4', text: 'What is the difference between RANK(), DENSE_RANK(), and ROW_NUMBER()?', options: ['They all give the same result', 'ROW_NUMBER gives unique sequential numbers; RANK gives same rank for ties with gaps; DENSE_RANK gives same rank for ties without gaps', 'RANK is always preferred', 'They only work with ORDER BY'], correctAnswer: 1, explanation: 'For values [10, 20, 20, 30]: ROW_NUMBER: 1,2,3,4. RANK: 1,2,2,4 (gap after ties). DENSE_RANK: 1,2,2,3 (no gap). Choose based on whether you need unique numbers, gaps, or consecutive ranks.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-5', text: 'What is a Common Table Expression (CTE)?', options: ['A permanent table', 'A named temporary result set defined with WITH clause that can be referenced within a query, improving readability and enabling recursion', 'A stored procedure', 'An index type'], correctAnswer: 1, explanation: 'CTEs use WITH clause to define named subqueries: WITH cte AS (SELECT ...) SELECT * FROM cte. Benefits: improved readability, can be referenced multiple times, supports recursion (WITH RECURSIVE). Scope is limited to the immediately following statement.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-6', text: 'What is a subquery and when would you use one?', options: ['A backup query', 'A query nested inside another query, used for filtering, computing values, or creating derived tables when a single query cannot express the logic', 'A faster alternative to JOINs', 'Only for DELETE operations'], correctAnswer: 1, explanation: 'Subqueries are queries within queries. Types: scalar (returns single value), row (returns one row), table (returns a table). Used with IN, EXISTS, comparison operators. Example: SELECT * FROM emp WHERE salary > (SELECT AVG(salary) FROM emp).', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-7', text: 'What does COALESCE() do in SQL?', options: ['Merges tables', 'Returns the first non-NULL value from a list of arguments, useful for handling missing data', 'Combines columns', 'Counts non-null values'], correctAnswer: 1, explanation: 'COALESCE(val1, val2, ...) returns the first non-NULL argument. Example: COALESCE(phone, email, "no contact") returns phone if not null, otherwise email, otherwise "no contact". Essential for handling NULL values in queries.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-8', text: 'What is the difference between UNION and UNION ALL?', options: ['They are identical', 'UNION removes duplicate rows from the combined result; UNION ALL keeps all rows including duplicates and is faster', 'UNION ALL removes duplicates', 'UNION is for different tables only'], correctAnswer: 1, explanation: 'UNION combines results and removes duplicates (requires sorting, slower). UNION ALL combines all rows including duplicates (faster). Use UNION ALL when you know there are no duplicates or want to keep them.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-9', text: 'What is an index in a database and why is it important?', options: ['A table of contents for the database', 'A data structure (usually B-tree) that speeds up data retrieval by allowing the database to find rows without scanning the entire table, at the cost of extra storage and slower writes', 'A unique identifier for rows', 'A backup mechanism'], correctAnswer: 1, explanation: 'Indexes create sorted data structures (B-tree, hash) for fast lookups. Without index: full table scan O(n). With index: O(log n) for B-tree. Trade-offs: faster reads, slower writes (must update index), extra storage. Index columns used in WHERE, JOIN, ORDER BY.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },
  { id: 'sql-10', text: 'Write a query to find the second highest salary from an employees table.', options: ['SELECT MAX(salary) FROM employees', 'SELECT MAX(salary) FROM employees WHERE salary < (SELECT MAX(salary) FROM employees)', 'SELECT salary FROM employees LIMIT 2', 'SELECT MIN(salary) FROM employees'], correctAnswer: 1, explanation: 'The subquery finds the maximum salary, then the outer query finds the maximum salary that is less than the overall maximum. Alternative: use DENSE_RANK() or OFFSET: SELECT DISTINCT salary FROM employees ORDER BY salary DESC LIMIT 1 OFFSET 1.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-basics' },

  // sql-advanced
  { id: 'sqla-1', text: 'How do you calculate a running total in SQL?', options: ['Use GROUP BY', 'SUM(amount) OVER (ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)', 'Use a subquery with SUM', 'Running totals are not possible in SQL'], correctAnswer: 1, explanation: 'Window function with frame: SUM(amount) OVER (ORDER BY date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) computes cumulative sum. ROWS UNBOUNDED PRECEDING is the default frame, so SUM(amount) OVER (ORDER BY date) also works.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-2', text: 'What is a self-join and when would you use it?', options: ['Joining a table with itself', 'Joining a table to itself using aliases, useful for comparing rows within the same table (e.g., finding employees who earn more than their managers)', 'A join that creates itself', 'An automatic join'], correctAnswer: 1, explanation: 'A self-join joins a table to itself: SELECT e.name, m.name FROM employees e JOIN employees m ON e.manager_id = m.id. Useful for hierarchical data, finding duplicates, comparing rows within the same table.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-3', text: 'What is the difference between correlated and non-correlated subqueries?', options: ['They perform the same', 'A correlated subquery references the outer query and executes once per row; a non-correlated subquery is independent and executes once total', 'Non-correlated subqueries are always slower', 'Correlated subqueries only work with EXISTS'], correctAnswer: 1, explanation: 'Non-correlated: independent of outer query, runs once (SELECT * FROM emp WHERE dept_id IN (SELECT id FROM dept)). Correlated: references outer query, runs per row (SELECT * FROM emp e WHERE salary > (SELECT AVG(salary) FROM emp WHERE dept_id = e.dept_id)).', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-4', text: 'How do you find duplicate rows in a table?', options: ['SELECT DISTINCT', 'SELECT columns, COUNT(*) FROM table GROUP BY columns HAVING COUNT(*) > 1', 'Use UNION', 'SELECT * WHERE duplicate = true'], correctAnswer: 1, explanation: 'Group by the columns that should be unique, then filter groups with count > 1. To delete duplicates keeping one: use ROW_NUMBER() OVER (PARTITION BY duplicate_cols ORDER BY id) and delete rows where row_number > 1.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer', 'ai_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-5', text: 'What is a pivot table in SQL?', options: ['A rotating table', 'Transforming rows into columns (or vice versa) to reshape data for analysis, often using CASE WHEN with aggregation or the PIVOT operator', 'A temporary table', 'A table with a primary key'], correctAnswer: 1, explanation: 'Pivoting turns row values into columns. Using CASE: SELECT category, SUM(CASE WHEN year=2023 THEN revenue END) as y2023, SUM(CASE WHEN year=2024 THEN revenue END) as y2024 FROM sales GROUP BY category. Some databases have native PIVOT syntax.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-6', text: 'What is the LAG() window function used for?', options: ['Measuring query latency', 'Accessing a value from a previous row in the result set without a self-join, useful for calculating differences between consecutive rows', 'Creating lag in execution', 'Delaying query results'], correctAnswer: 1, explanation: 'LAG(column, offset, default) OVER (ORDER BY ...) returns the value from a previous row. LEAD() returns the value from a following row. Useful for: period-over-period changes, time gaps between events, sequential comparisons.', difficulty: 'medium', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['midsize', 'large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-7', text: 'How would you calculate a 7-day moving average in SQL?', options: ['Use AVG() alone', 'AVG(value) OVER (ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)', 'GROUP BY week', 'It cannot be done in SQL'], correctAnswer: 1, explanation: 'Use a window function with a frame: AVG(value) OVER (ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW). This computes the average of the current row and 6 preceding rows. Use RANGE for date-based windows when dates might have gaps.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-8', text: 'What is query optimization and what are common strategies?', options: ['Making queries shorter', 'Improving query performance through indexing, avoiding SELECT *, using EXISTS over IN for large subqueries, optimizing JOINs, and reading execution plans', 'Always using stored procedures', 'Increasing server RAM'], correctAnswer: 1, explanation: 'Strategies: create indexes on WHERE/JOIN columns, avoid SELECT * (select only needed columns), use EXISTS over IN for large subqueries, avoid functions in WHERE (prevents index use), use EXPLAIN/execution plans, denormalize for read-heavy workloads.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-9', text: 'What are the different types of SQL constraints?', options: ['Only PRIMARY KEY', 'PRIMARY KEY, FOREIGN KEY, UNIQUE, NOT NULL, CHECK, and DEFAULT constraints ensure data integrity', 'Constraints are optional', 'Only for creating tables'], correctAnswer: 1, explanation: 'PRIMARY KEY: unique identifier. FOREIGN KEY: referential integrity. UNIQUE: no duplicates. NOT NULL: required field. CHECK: custom conditions (age > 0). DEFAULT: default value. These enforce data integrity at the database level.', difficulty: 'easy', roles: ['data_scientist', 'ml_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['startup', 'midsize', 'large'], unitId: 'sql-data', lessonId: 'sql-advanced' },
  { id: 'sqla-10', text: 'What is the EXPLAIN command used for?', options: ['Documenting queries', 'Showing the execution plan of a query, including how tables are scanned, which indexes are used, and estimated costs, helping identify performance bottlenecks', 'Explaining SQL syntax', 'A comment system'], correctAnswer: 1, explanation: 'EXPLAIN (or EXPLAIN ANALYZE in PostgreSQL) shows the query execution plan: table scan type (seq scan vs index scan), join algorithms (nested loop, hash, merge), estimated rows and cost. Essential for diagnosing slow queries and verifying index usage.', difficulty: 'hard', roles: ['data_scientist', 'ml_engineer', 'mlops_engineer'], category: 'technical', companySizes: ['large', 'faang'], unitId: 'sql-data', lessonId: 'sql-advanced' },
];
