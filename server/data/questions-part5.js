// Part 5: Advanced ML interview coding + systems questions
export const questionsPart5 = [
  // Injected into existing units
  {
    id: 'dl-rnn-adv-1',
    text: 'In an interview, when is an LSTM usually preferred over a vanilla RNN?',
    options: ['When sequence length is tiny and memory is irrelevant', 'When long-range dependencies are important and vanishing gradients are a concern', 'When only tabular static data is available', 'When model interpretability is the only requirement'],
    correctAnswer: 1,
    explanation: 'LSTMs add gating mechanisms that preserve gradients better across long sequences.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'deep_learning',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'deep-learning',
    lessonId: 'rnn-sequence',
  },
  {
    id: 'dl-rnn-adv-2',
    text: 'For a multimodal system combining text and time-series signals, what is a practical architecture pattern?',
    options: ['Train independent models and average random outputs', 'Encode each modality separately, fuse representations, then train a joint head', 'Use only the text modality because it is easier', 'Use nearest-neighbor search only'],
    correctAnswer: 1,
    explanation: 'Separate encoders with late/intermediate fusion is a common and scalable multimodal pattern.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'deep_learning',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'deep-learning',
    lessonId: 'rnn-sequence',
  },
  {
    id: 'llm-rag-adv-1',
    text: 'What is the primary role of retrieval in a RAG pipeline?',
    options: ['To train the model from scratch', 'To provide grounding context at inference time', 'To replace tokenization', 'To remove prompt templates'],
    correctAnswer: 1,
    explanation: 'RAG retrieves external context to ground model answers without retraining the base model.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'nlp',
    lessonId: 'llms',
  },
  {
    id: 'llm-rag-adv-2',
    text: 'In production LLM systems, when is prompt engineering usually better than fine-tuning?',
    options: ['When you need quick iteration and behavior control without model retraining', 'When domain labels are massive and stable for months', 'When GPU memory is unlimited', 'When latency does not matter'],
    correctAnswer: 0,
    explanation: 'Prompt changes are fast, reversible, and often sufficient for many behavior adjustments.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'nlp',
    lessonId: 'llms',
  },
  {
    id: 'llm-rag-adv-3',
    text: 'For GPT-style decoding, what is a key difference between top-k and nucleus (top-p) sampling?',
    options: ['Top-k uses fixed probability mass, top-p uses fixed token count', 'Top-k uses fixed token count, top-p uses dynamic token set based on cumulative probability', 'They are identical in all cases', 'Top-p is greedy decoding only'],
    correctAnswer: 1,
    explanation: 'Top-k keeps k candidates; top-p adapts candidate set by probability mass threshold.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'nlp',
    lessonId: 'llms',
  },
  {
    id: 'sql-adv-ml-1',
    text: 'You need training features from event logs. Which SQL pattern is most common for user-level aggregates?',
    options: ['Cross join all tables without keys', 'Window functions and grouped aggregations on user/time keys', 'Delete duplicates and sample randomly', 'Use only SELECT * with no filters'],
    correctAnswer: 1,
    explanation: 'Window functions + grouped aggregates are standard for feature generation on temporal data.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'sql-data',
    lessonId: 'sql-advanced',
  },
  {
    id: 'sql-adv-ml-2',
    text: 'What is a common leakage risk when writing SQL for training data?',
    options: ['Using CTEs', 'Including future information relative to prediction timestamp', 'Using aliases', 'Partitioning by date'],
    correctAnswer: 1,
    explanation: 'Feature leakage often occurs when future events are included in historical training snapshots.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'sql-data',
    lessonId: 'sql-advanced',
  },
  {
    id: 'np-pd-adv-1',
    text: 'In a pandas/NumPy preprocessing pipeline interview task, what is usually most important?',
    options: ['Micro-optimizing every line immediately', 'Clear, reproducible transformations with missing-value handling', 'Using as many external libraries as possible', 'Avoiding vectorization'],
    correctAnswer: 1,
    explanation: 'Interviewers typically value correctness, reproducibility, and clear handling of data quality issues.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'data_processing',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-pd-adv-2',
    text: 'In EDA, why inspect both correlation and covariance?',
    options: ['They are exactly the same metric', 'Covariance keeps scale information while correlation is normalized', 'Correlation is always more reliable', 'Covariance does not require numerical data'],
    correctAnswer: 1,
    explanation: 'Covariance magnitude depends on variable scales; correlation normalizes to [-1, 1].',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'statistics',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'mlops-mon-adv-1',
    text: 'Which monitoring setup is most useful for an ML inference pipeline?',
    options: ['Only server CPU metrics', 'Data drift, prediction distribution, latency, error rate, and business KPI monitoring', 'Only model version logs', 'Only daily email summaries'],
    correctAnswer: 1,
    explanation: 'Production ML monitoring should cover model behavior, system health, and business impact together.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'mlops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'mlops',
    lessonId: 'monitoring-maintenance',
  },
  {
    id: 'mlops-mon-adv-2',
    text: 'A good first action when model metrics degrade after deployment is to:',
    options: ['Retrain immediately with all data', 'Compare serving features and data schema against training expectations', 'Disable monitoring alerts', 'Rollback and never investigate'],
    correctAnswer: 1,
    explanation: 'Many incidents are caused by feature/schema drift between training and serving paths.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'mlops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'mlops',
    lessonId: 'monitoring-maintenance',
  },

  // New unit: ml-interview-coding
  {
    id: 'mic-py-1',
    text: 'In coding screens, why are simple array/hashmap problems (e.g., missing seconds, longest consecutive sequence) common for ML engineers?',
    options: ['They test deep GPU kernel programming', 'They test core problem-solving, data structures, and code clarity under time pressure', 'They are unrelated and random', 'They primarily test UI design'],
    correctAnswer: 1,
    explanation: 'Interview loops often verify fundamentals regardless of domain specialization.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },
  {
    id: 'mic-py-2',
    text: 'For implementing logistic regression in NumPy, what is essential in each training step?',
    options: ['Forward pass only', 'Compute predictions, loss gradient, and update weights', 'Randomly shuffle labels', 'Convert to SQL query'],
    correctAnswer: 1,
    explanation: 'A working implementation needs prediction, gradient computation, and parameter updates.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },
  {
    id: 'mic-py-3',
    text: 'When implementing k-means in NumPy, what convergence criterion is commonly used?',
    options: ['Number of classes equals 2', 'Centroids stop changing (or change below threshold)', 'Dataset size doubles', 'Loss becomes exactly zero'],
    correctAnswer: 1,
    explanation: 'K-means typically stops when centroid movement is minimal or max iterations reached.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },
  {
    id: 'mic-py-4',
    text: 'If asked to write a transformer block in PyTorch, which sequence is correct?',
    options: ['MLP -> embeddings -> optimizer step', 'Self-attention -> add&norm -> feed-forward -> add&norm', 'Convolution -> pooling -> RNN', 'Tokenization -> SQL join -> softmax'],
    correctAnswer: 1,
    explanation: 'Standard transformer layers stack attention and feed-forward sublayers with residual + normalization.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },
  {
    id: 'mic-py-5',
    text: 'In distributed model debugging interviews, what is a high-value first check?',
    options: ['Change optimizer randomly', 'Verify tensor shapes, synchronization points, and deterministic seeds', 'Delete gradient clipping', 'Increase batch size without limit'],
    correctAnswer: 1,
    explanation: 'Many distributed bugs come from shape mismatches, race conditions, and nondeterministic behavior.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },
  {
    id: 'mic-py-6',
    text: 'In an interview coding exercise, when should you optimize for readability over micro-performance?',
    options: ['Never', 'Usually first, unless explicit performance constraints are provided', 'Only for SQL tasks', 'Only for recursion problems'],
    correctAnswer: 1,
    explanation: 'Interviewers typically evaluate correctness and communication before low-level optimization.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'coding',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'python-ml-coding',
  },

  {
    id: 'mic-sql-1',
    text: 'If asked to prepare SQL data for model fitting, what should be enforced first?',
    options: ['No primary keys', 'Deterministic joins and clear entity granularity', 'Use nested subqueries everywhere', 'Drop all null rows blindly'],
    correctAnswer: 1,
    explanation: 'Model datasets need stable joins and an explicit row-level entity definition.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },
  {
    id: 'mic-sql-2',
    text: 'Which SQL feature is most useful for deriving rolling features?',
    options: ['UNION ALL only', 'Window functions with PARTITION BY and ORDER BY', 'DELETE statements', 'ALTER TABLE'],
    correctAnswer: 1,
    explanation: 'Rolling features are commonly implemented using window functions.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },
  {
    id: 'mic-sql-3',
    text: 'For training/validation splits in SQL, a reliable strategy is:',
    options: ['Random split with future timestamps mixed into train', 'Time-based split preserving chronological order', 'Use only latest week for all sets', 'No split needed'],
    correctAnswer: 1,
    explanation: 'Time-aware splits reduce leakage in many real-world ML tasks.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },
  {
    id: 'mic-sql-4',
    text: 'When a SQL query for feature generation is too slow, what is a practical first step?',
    options: ['Rewrite in Python immediately', 'Check execution plan and indexing on join/filter keys', 'Increase timeout only', 'Duplicate all tables'],
    correctAnswer: 1,
    explanation: 'Execution plans and indexes often reveal the dominant bottlenecks quickly.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'data_scientist', 'mlops_engineer'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },
  {
    id: 'mic-sql-5',
    text: 'For mixed SQL + ML interviews, what is interviewers’ key expectation?',
    options: ['Perfect query memorization', 'Ability to translate business question into clean data pipeline logic', 'Knowledge of one vendor syntax only', 'No error handling'],
    correctAnswer: 1,
    explanation: 'Strong candidates connect business intent to robust feature extraction logic.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },
  {
    id: 'mic-sql-6',
    text: 'Why include data quality checks in SQL-to-model pipelines?',
    options: ['To increase query latency intentionally', 'To catch null spikes, duplicates, and schema drift before model training', 'To avoid joins', 'To replace model evaluation'],
    correctAnswer: 1,
    explanation: 'Data quality checks prevent silent failures and unstable model behavior.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer', 'data_scientist'],
    category: 'sql_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'sql-ml-coding',
  },

  {
    id: 'mic-algo-1',
    text: 'In the binary tree path sum problem, what is a canonical approach?',
    options: ['Greedy choose max node every level', 'DFS recursion carrying running sum to leaf nodes', 'Sort tree by value', 'Use SQL window functions'],
    correctAnswer: 1,
    explanation: 'DFS with running sum is the standard and clear solution pattern.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },
  {
    id: 'mic-algo-2',
    text: 'For merge intervals, why sort by start time first?',
    options: ['To reduce memory to O(1) always', 'To process overlaps in one pass', 'To avoid edge cases', 'It is optional and unrelated'],
    correctAnswer: 1,
    explanation: 'Sorting enables linear sweep merging of overlapping intervals.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },
  {
    id: 'mic-algo-3',
    text: 'Longest consecutive sequence in O(n) time is typically solved with:',
    options: ['Nested loops over sorted list', 'Hash set start-point expansion', 'Binary tree balancing', 'Dynamic programming table by index only'],
    correctAnswer: 1,
    explanation: 'A hash set enables checking sequence starts and expanding in amortized O(n).',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer', 'data_scientist'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },
  {
    id: 'mic-algo-4',
    text: 'For “missing seconds in array” style tasks, what should be clarified before coding?',
    options: ['Preferred IDE theme', 'Whether duplicates, unsorted input, and range bounds are allowed', 'CPU cache line size', 'Cloud vendor'],
    correctAnswer: 1,
    explanation: 'Clarifying constraints avoids incorrect assumptions and rework.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },
  {
    id: 'mic-algo-5',
    text: 'In whiteboard coding rounds, why discuss time/space complexity aloud?',
    options: ['It is discouraged', 'It demonstrates tradeoff awareness and communication', 'It replaces tests', 'It guarantees an offer'],
    correctAnswer: 1,
    explanation: 'Interviewers assess reasoning and communication, not just final code.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist', 'ai_engineer'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },
  {
    id: 'mic-algo-6',
    text: 'A robust coding interview strategy under time pressure is:',
    options: ['Code silently end-to-end first', 'Clarify requirements, outline approach, code incrementally, test edge cases', 'Optimize before correctness', 'Skip test cases'],
    correctAnswer: 1,
    explanation: 'Structured execution reduces mistakes and makes your thought process visible.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist', 'ai_engineer'],
    category: 'algorithms',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-interview-coding',
    lessonId: 'algorithms-for-ml-screening',
  },

  // New unit: advanced-ml-theory
  {
    id: 'amt-opt-1',
    text: 'Why does gradient descent require a learning rate?',
    options: ['To decide model architecture', 'To control update step size and convergence behavior', 'To select train/test split', 'To set random seed'],
    correctAnswer: 1,
    explanation: 'Learning rate governs optimization dynamics and stability.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist', 'ai_engineer'],
    category: 'optimization',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },
  {
    id: 'amt-opt-2',
    text: 'Why is setting a random seed useful in experiments?',
    options: ['It improves model accuracy automatically', 'It improves reproducibility and debugging across runs', 'It removes all randomness from hardware', 'It replaces validation'],
    correctAnswer: 1,
    explanation: 'Seeds make stochastic components repeatable for fair comparisons.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'optimization',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },
  {
    id: 'amt-opt-3',
    text: 'If model training oscillates and diverges, a common first adjustment is:',
    options: ['Increase learning rate', 'Reduce learning rate or add gradient clipping', 'Remove normalization', 'Use fewer features blindly'],
    correctAnswer: 1,
    explanation: 'Large updates can destabilize training; smaller steps and clipping improve stability.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'optimization',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },
  {
    id: 'amt-opt-4',
    text: 'In model evaluation, why is covariance alone often insufficient compared with correlation?',
    options: ['Covariance is always normalized', 'Covariance is scale-dependent and can be hard to compare across features', 'Correlation requires no data', 'Correlation is only for non-linear data'],
    correctAnswer: 1,
    explanation: 'Correlation provides normalized strength, making cross-feature comparisons easier.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'statistics',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },
  {
    id: 'amt-opt-5',
    text: 'When explaining model-fit reliability to an engineering manager, a strong focus is:',
    options: ['Only training loss', 'Generalization metrics, data quality, and failure modes', 'Framework brand', 'GPU count only'],
    correctAnswer: 1,
    explanation: 'Leads care about reliability and risk in production, not just training metrics.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'model_evaluation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },
  {
    id: 'amt-opt-6',
    text: 'What is a key practical reason to discuss data size during interviews?',
    options: ['It is irrelevant to architecture', 'It determines feasible model/design choices, latency, and infra cost', 'It only impacts SQL syntax', 'It changes binary tree algorithms'],
    correctAnswer: 1,
    explanation: 'Scale drives architecture and operational tradeoffs.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'system_design',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'optimization-and-statistics',
  },

  {
    id: 'amt-rep-1',
    text: 'How does PCA reduce dimensionality?',
    options: ['By removing random rows', 'By projecting data onto orthogonal directions with maximal variance', 'By training a neural net classifier', 'By selecting features with lowest variance only'],
    correctAnswer: 1,
    explanation: 'PCA finds principal components that capture major variance in lower-dimensional space.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'dimensionality_reduction',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },
  {
    id: 'amt-rep-2',
    text: 'LDA vs PCA: what is the most important distinction?',
    options: ['LDA is unsupervised, PCA is supervised', 'LDA uses class labels to maximize separability; PCA is unsupervised variance maximization', 'They are equivalent', 'PCA only works for text'],
    correctAnswer: 1,
    explanation: 'LDA is supervised and class-separation-oriented, while PCA is unsupervised.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'dimensionality_reduction',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },
  {
    id: 'amt-rep-3',
    text: 'When might ANN (feed-forward) be preferred over RNN/LSTM?',
    options: ['When order/sequence is critical', 'For fixed-length tabular features where sequential dependency is weak', 'For graph-only inputs', 'For time-dependent language modeling only'],
    correctAnswer: 1,
    explanation: 'ANNs are often strong baselines for non-sequential tabular tasks.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'deep_learning',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },
  {
    id: 'amt-rep-4',
    text: 'In EDA-heavy rounds, what is an interviewer often testing beyond tooling?',
    options: ['Color palette choice', 'Ability to form hypotheses, detect anomalies, and communicate implications', 'How many plots you can create', 'Memory of every statistical formula'],
    correctAnswer: 1,
    explanation: 'EDA interviews assess structured reasoning and business-relevant interpretation.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'eda',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },
  {
    id: 'amt-rep-5',
    text: 'For paper-implementation interview tasks, what is the best starting strategy?',
    options: ['Implement full paper end-to-end immediately', 'Extract core equations/components and build a minimal faithful baseline first', 'Skip assumptions section', 'Tune hyperparameters before coding'],
    correctAnswer: 1,
    explanation: 'A minimal faithful implementation reduces complexity and surfaces core issues quickly.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'research_to_prod',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },
  {
    id: 'amt-rep-6',
    text: 'If a model improves offline but degrades online, one likely cause is:',
    options: ['GPU too new', 'Offline dataset mismatch with online traffic distribution', 'Too many comments in code', 'Using Python instead of C++'],
    correctAnswer: 1,
    explanation: 'Distribution mismatch is a common reason for offline/online performance gaps.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'production_ml',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'representation-and-dimensionality',
  },

  {
    id: 'amt-rag-1',
    text: 'Which is typically a stronger reason to fine-tune than prompt engineer?',
    options: ['Need fast iterative tone tweaks', 'Need durable domain adaptation with stable labeled data', 'Need lower token usage only', 'Need quick A/B test only'],
    correctAnswer: 1,
    explanation: 'Fine-tuning is often justified when repeated domain behavior improvements are needed at scale.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },
  {
    id: 'amt-rag-2',
    text: 'In RAG system design interviews, what is a high-value discussion point?',
    options: ['Only UI color choices', 'Chunking strategy, embedding quality, retrieval eval, and failure analysis', 'Only model size', 'Only vector DB brand'],
    correctAnswer: 1,
    explanation: 'Robust RAG design depends on retrieval quality and measurable failure handling.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },
  {
    id: 'amt-rag-3',
    text: 'For LLM tools/packages questions, what demonstrates maturity?',
    options: ['Listing package names only', 'Explaining package tradeoffs, observability, and production constraints', 'Memorizing API docs', 'Avoiding all ecosystem tools'],
    correctAnswer: 1,
    explanation: 'Interviewers value practical tradeoff reasoning over tool-name recall.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },
  {
    id: 'amt-rag-4',
    text: 'What is a common risk of aggressive top-k truncation in sampling?',
    options: ['Guaranteed factuality', 'Reduced diversity and potential degeneration', 'Lower latency always', 'Better retrieval precision'],
    correctAnswer: 1,
    explanation: 'Low k can over-constrain decoding, hurting diversity and quality.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },
  {
    id: 'amt-rag-5',
    text: 'In an interview, how should you justify choosing RAG over fine-tuning?',
    options: ['RAG is always better', 'RAG can update knowledge without retraining and improve traceability for external facts', 'Fine-tuning is outdated', 'RAG avoids evaluation needs'],
    correctAnswer: 1,
    explanation: 'RAG is often preferred when freshness and grounding on external corpora are key.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'llm',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },
  {
    id: 'amt-rag-6',
    text: 'Which interview answer is strongest for “how to fit the model”?',
    options: ['Just call fit() and stop', 'Define objective, prepare splits/features, train, validate, analyze errors, and plan monitoring', 'Tune only one hyperparameter', 'Use default settings blindly'],
    correctAnswer: 1,
    explanation: 'A full modeling lifecycle answer signals production readiness.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'modeling',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'advanced-ml-theory',
    lessonId: 'llm-and-rag-theory',
  },

  // New unit: ml-systems-in-practice
  {
    id: 'msp-flow-1',
    text: 'When comparing streaming vs batch pipelines, which tradeoff is most central?',
    options: ['Language syntax only', 'Latency/freshness vs complexity/cost', 'Model architecture only', 'Database license type'],
    correctAnswer: 1,
    explanation: 'Streaming improves freshness but increases system complexity and operational overhead.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'data_engineering',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },
  {
    id: 'msp-flow-2',
    text: 'Ingestion pipeline interview question: why might MongoDB be selected?',
    options: ['Because it is relational and strict-schema only', 'Document model flexibility for semi-structured data and rapid iteration', 'Because it guarantees zero ops', 'Because SQL cannot store JSON'],
    correctAnswer: 1,
    explanation: 'MongoDB is a document database often chosen for schema-flexible ingestion workloads.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer', 'data_scientist'],
    category: 'data_engineering',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },
  {
    id: 'msp-flow-3',
    text: 'A robust data flow explanation in interviews should include:',
    options: ['Only data source names', 'Source -> ingestion -> storage -> feature generation -> training/serving -> monitoring', 'Only model endpoint', 'Only dashboard metrics'],
    correctAnswer: 1,
    explanation: 'End-to-end data flow clarity signals strong systems understanding.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'system_design',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },
  {
    id: 'msp-flow-4',
    text: 'Why do teams often use cloud services over local systems for ML production?',
    options: ['Cloud is always cheaper for every workload', 'Elastic scaling, managed services, reliability tooling, and team collaboration', 'Local systems cannot run Python', 'Cloud removes need for security'],
    correctAnswer: 1,
    explanation: 'Cloud platforms simplify scaling and operations, especially for collaborative production systems.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'mlops_engineer', 'ai_engineer'],
    category: 'cloud',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },
  {
    id: 'msp-flow-5',
    text: 'If batch processing is chosen, what is a key risk to address?',
    options: ['Model cannot be evaluated', 'Data staleness and delayed reaction to distribution shifts', 'No storage needed', 'No scheduling required'],
    correctAnswer: 1,
    explanation: 'Batch systems can lag behind real-time changes unless monitoring and cadence are designed well.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'data_engineering',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },
  {
    id: 'msp-flow-6',
    text: 'When discussing data volume in interviews, what should you tie it to?',
    options: ['Team size only', 'Storage choices, partitioning strategy, and compute/resource planning', 'UI framework', 'Coding language preference'],
    correctAnswer: 1,
    explanation: 'Data volume directly impacts architecture and operational planning.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'system_design',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'data-flow-and-pipelines',
  },

  {
    id: 'msp-prod-1',
    text: 'In production, when should you choose a simpler model over a complex one?',
    options: ['Never', 'When it meets target performance with lower latency/cost and better reliability', 'Only when interviews ask', 'Only for tabular data'],
    correctAnswer: 1,
    explanation: 'Production model choice is about end-to-end utility, not complexity alone.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'modeling',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },
  {
    id: 'msp-prod-2',
    text: 'For manager rounds, what is the strongest way to explain “size of data worked upon”?',
    options: ['Only row count', 'Data volume + velocity + schema complexity + update frequency + SLA implications', 'Only storage format', 'Only number of tables'],
    correctAnswer: 1,
    explanation: 'A complete answer links data scale to system and product constraints.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer', 'data_scientist'],
    category: 'system_design',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },
  {
    id: 'msp-prod-3',
    text: 'A production-ready multimodal model answer should mention:',
    options: ['Only architecture diagrams', 'Data alignment, modality-specific preprocessing, fusion strategy, and monitoring by modality', 'Only GPU size', 'Only prompt templates'],
    correctAnswer: 1,
    explanation: 'Multimodal systems fail if data alignment and per-modality quality are ignored.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'system_design',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },
  {
    id: 'msp-prod-4',
    text: 'When fitting a model in coding interviews, what often earns high marks?',
    options: ['Calling a single library API without checks', 'Feature prep, split strategy, baseline model, metric choice, and error analysis', 'Hyperparameter search first', 'Skipping validation'],
    correctAnswer: 1,
    explanation: 'Interviewers look for workflow rigor, not just API familiarity.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'data_scientist'],
    category: 'modeling',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },
  {
    id: 'msp-prod-5',
    text: 'For ANN/RNN/LSTM selection in practice, what should guide choice most?',
    options: ['Model popularity', 'Data structure, temporal dependency patterns, and latency constraints', 'Cloud vendor', 'Random seed'],
    correctAnswer: 1,
    explanation: 'Model family should match data characteristics and operational constraints.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'deep_learning',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },
  {
    id: 'msp-prod-6',
    text: 'In manager interviews, a good “monitoring pipeline” answer includes:',
    options: ['Only dashboard screenshots', 'Data checks, model metrics, infra SLAs, alert routing, and ownership/on-call process', 'Only retraining cadence', 'Only one KPI'],
    correctAnswer: 1,
    explanation: 'Strong monitoring design combines metrics, process, and accountability.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'mlops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'modeling-in-production',
  },

  {
    id: 'msp-ops-1',
    text: 'What is a practical production metric for retraining triggers?',
    options: ['CPU temperature only', 'Prediction drift + business KPI degradation beyond threshold', 'Number of commits', 'Interview score'],
    correctAnswer: 1,
    explanation: 'Retraining decisions should be driven by statistically meaningful drift and outcome impact.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'mlops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  {
    id: 'msp-ops-2',
    text: 'In platform operations, why keep batch and streaming paths explicitly documented?',
    options: ['For compliance only', 'To avoid ownership ambiguity and reduce incident MTTR', 'To increase complexity', 'To eliminate tests'],
    correctAnswer: 1,
    explanation: 'Clear ownership and data contracts speed up incident response.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'ops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  {
    id: 'msp-ops-3',
    text: 'For cloud vs local system tradeoff questions, what is balanced?',
    options: ['Cloud is always superior', 'Local is always superior', 'Choose based on reliability, compliance, cost, latency, and team velocity constraints', 'Choose based on interview trend'],
    correctAnswer: 2,
    explanation: 'There is no universal winner; decisions are context- and constraint-dependent.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'mlops_engineer', 'ai_engineer'],
    category: 'cloud',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  {
    id: 'msp-ops-4',
    text: 'For ingestion pipelines with changing schemas, what is a robust pattern?',
    options: ['Hard-fail every schema change with no metadata', 'Schema contracts + validation + versioned transformations', 'Ignore schema changes', 'Convert all fields to strings forever'],
    correctAnswer: 1,
    explanation: 'Schema governance and versioned transforms improve reliability at scale.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer', 'data_scientist'],
    category: 'data_engineering',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  {
    id: 'msp-ops-5',
    text: 'In ML platform operations, why is feature-store consistency important?',
    options: ['It only affects training speed', 'It reduces train-serve skew and inconsistent predictions', 'It removes need for monitoring', 'It is only needed for CV models'],
    correctAnswer: 1,
    explanation: 'Consistency across offline/online features is critical to predictable production behavior.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'mlops_engineer'],
    category: 'mlops',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  {
    id: 'msp-ops-6',
    text: 'A practical reason for managed cloud services in ML teams is:',
    options: ['Eliminate all architecture decisions', 'Reduce undifferentiated ops work so teams focus on model/product value', 'Avoid cost monitoring', 'Replace model evaluation'],
    correctAnswer: 1,
    explanation: 'Managed services help teams focus on business logic rather than infrastructure maintenance.',
    difficulty: 'easy',
    roles: ['ml_engineer', 'mlops_engineer', 'ai_engineer'],
    category: 'cloud',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ml-systems-in-practice',
    lessonId: 'monitoring-and-platform-ops',
  },
  // ====== UNIT: delivery-operations ======
  // Lesson: ci-cd-procedures
  {
    id: 'do-cicd-1',
    text: 'What is the main purpose of running tests in a CI pipeline before merge?',
    options: ['To increase server usage', 'To catch regressions early and reduce production risk', 'To avoid code reviews', 'To replace monitoring'],
    correctAnswer: 1,
    explanation: 'CI test gates reduce the chance of broken code reaching production by validating behavior before merge.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'ci-cd-procedures',
  },
  {
    id: 'do-cicd-2',
    text: 'A useful CI optimization for large repositories is:',
    options: ['Re-running every job on every commit', 'Skipping all tests on feature branches', 'Running changed-scope tests first and full suite on merge', 'Disabling linting permanently'],
    correctAnswer: 2,
    explanation: 'Scoped checks on PRs and full validation on merge keeps feedback fast while preserving reliability.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'ci-cd-procedures',
  },
  {
    id: 'do-cicd-3',
    text: 'Why should secrets be injected at runtime in CI/CD rather than hardcoded in source?',
    options: ['It makes logs easier to read', 'It prevents accidental credential leaks and simplifies rotation', 'It improves UI performance', 'It removes the need for audits'],
    correctAnswer: 1,
    explanation: 'Runtime secret management lowers leakage risk and supports secure rotation and access control.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'ci-cd-procedures',
  },
  {
    id: 'do-cicd-4',
    text: 'Which policy best protects the main branch in a collaborative team?',
    options: ['Direct pushes by anyone', 'Required reviews and passing checks before merge', 'Merge without tests for urgent features', 'Only commit messages are validated'],
    correctAnswer: 1,
    explanation: 'Branch protection with review and CI checks is a standard reliability safeguard.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'ci-cd-procedures',
  },
  {
    id: 'do-cicd-5',
    text: 'What is the key value of artifact versioning in a release pipeline?',
    options: ['It removes the need for logs', 'It enables reproducible builds and rollback confidence', 'It guarantees zero incidents', 'It replaces QA testing'],
    correctAnswer: 1,
    explanation: 'Versioned artifacts make deployments traceable, reproducible, and easier to roll back safely.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'ci-cd-procedures',
  },

  // Lesson: deployment-strategies
  {
    id: 'do-deploy-1',
    text: 'In blue-green deployment, traffic is switched between:',
    options: ['Two identical production environments', 'Two different code branches', 'Two monitoring dashboards', 'Two databases with different schemas'],
    correctAnswer: 0,
    explanation: 'Blue-green keeps two live environments so cutover and rollback are quick and controlled.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'deployment-strategies',
  },
  {
    id: 'do-deploy-2',
    text: 'Canary releases are primarily used to:',
    options: ['Reduce build time', 'Gradually expose changes to a small audience and monitor impact', 'Eliminate feature flags', 'Avoid automated tests'],
    correctAnswer: 1,
    explanation: 'Canary deploys reduce blast radius by validating new behavior on limited traffic before full rollout.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'deployment-strategies',
  },
  {
    id: 'do-deploy-3',
    text: 'A safe rollback plan should be prepared:',
    options: ['Only after a failed deployment', 'Before deployment with validated rollback steps', 'Only for major releases', 'Only when a customer complains'],
    correctAnswer: 1,
    explanation: 'Rollback readiness must exist before release to minimize downtime during incidents.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'deployment-strategies',
  },
  {
    id: 'do-deploy-4',
    text: 'What is the best first response if post-deploy error rates spike?',
    options: ['Ignore alerts for 30 minutes', 'Scale CPU immediately without investigation', 'Pause rollout and compare key telemetry to baseline', 'Delete recent logs'],
    correctAnswer: 2,
    explanation: 'Pausing rollout and evaluating baseline deviations prevents wider impact and guides triage.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'deployment-strategies',
  },
  {
    id: 'do-deploy-5',
    text: 'Feature flags in deployment are most useful for:',
    options: ['Replacing source control', 'Decoupling code release from feature exposure', 'Avoiding observability setup', 'Disabling testing'],
    correctAnswer: 1,
    explanation: 'Feature flags let teams ship safely and control exposure without redeploying.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'industry_practice',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'delivery-operations',
    lessonId: 'deployment-strategies',
  },

  // ====== UNIT: ai-systems-implementation ======
  // Lesson: model-ops-patterns
  {
    id: 'ai-impl-1',
    text: 'When choosing between a larger and smaller model for production, a key tradeoff is:',
    options: ['Color scheme vs uptime', 'Latency/cost vs capability/quality', 'Branch naming vs test coverage', 'CPU type vs code comments'],
    correctAnswer: 1,
    explanation: 'Model selection balances response quality with serving latency, throughput, and cost constraints.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'model-ops-patterns',
  },
  {
    id: 'ai-impl-2',
    text: 'A practical way to compare new model versions in production-like conditions is:',
    options: ['A/B or shadow testing with shared evaluation criteria', 'Asking only one internal reviewer', 'Deploying all versions to all users at once', 'Skipping offline evaluation entirely'],
    correctAnswer: 0,
    explanation: 'Controlled experiments with clear metrics reduce risk and support objective model upgrades.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'model-ops-patterns',
  },
  {
    id: 'ai-impl-3',
    text: 'For stable AI behavior in production, one important control is:',
    options: ['Prompt and response versioning with evaluation tracking', 'Frequent manual server restarts', 'Randomly rotating output formats', 'Removing all guardrails'],
    correctAnswer: 0,
    explanation: 'Versioned prompts/configs plus tracked evaluations improve reproducibility and debugging.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'model-ops-patterns',
  },
  {
    id: 'ai-impl-4',
    text: 'Why is output schema validation useful for LLM features?',
    options: ['It speeds up GPU clocks', 'It catches malformed outputs before downstream failures', 'It guarantees perfect model reasoning', 'It replaces user feedback'],
    correctAnswer: 1,
    explanation: 'Schema checks prevent malformed data from breaking dependent systems and workflows.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'model-ops-patterns',
  },
  {
    id: 'ai-impl-5',
    text: 'A robust fallback strategy for AI endpoints usually includes:',
    options: ['No retries and no timeouts', 'Retries, graceful degradation, and deterministic fallback paths', 'Only larger prompts', 'Ignoring provider outages'],
    correctAnswer: 1,
    explanation: 'Fallbacks preserve user experience during latency spikes or provider failures.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'model-ops-patterns',
  },

  // Lesson: agents-context-mcp
  {
    id: 'ai-acm-1',
    text: 'In agent systems, tool use should generally be:',
    options: ['Unrestricted for all users', 'Constrained by permissions and explicit policies', 'Disabled in production always', 'Randomized to improve creativity'],
    correctAnswer: 1,
    explanation: 'Policy and permission boundaries reduce misuse and security risks.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'agents-context-mcp',
  },
  {
    id: 'ai-acm-2',
    text: 'A common benefit of MCP-style integrations is:',
    options: ['Directly replacing all databases', 'Standardized access to external tools and context sources', 'Eliminating authentication needs', 'Removing the need for observability'],
    correctAnswer: 1,
    explanation: 'Standardized tool interfaces simplify integration and governance across context providers.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'agents-context-mcp',
  },
  {
    id: 'ai-acm-3',
    text: 'Context window management is important because:',
    options: ['Models ignore all long prompts', 'Too much low-quality context can degrade answer quality and cost', 'It only matters for image models', 'It has no effect after deployment'],
    correctAnswer: 1,
    explanation: 'Selecting relevant context improves precision while controlling latency and token cost.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'agents-context-mcp',
  },
  {
    id: 'ai-acm-4',
    text: 'For semantic retrieval quality, what usually helps most?',
    options: ['Bigger UI buttons', 'Consistent chunking strategy plus relevance evaluation', 'Disabling metadata', 'Using one giant document chunk'],
    correctAnswer: 1,
    explanation: 'Good chunking and relevance evaluation are core drivers of retrieval quality.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'agents-context-mcp',
  },
  {
    id: 'ai-acm-5',
    text: 'An effective multi-agent system should include:',
    options: ['Shared responsibility boundaries and handoff contracts', 'No orchestration layer', 'A single prompt with no state', 'Only one permission model for every task'],
    correctAnswer: 0,
    explanation: 'Clear task ownership and handoff protocols reduce duplication, conflicts, and errors.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'ai_implementation',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'ai-systems-implementation',
    lessonId: 'agents-context-mcp',
  },

  // ====== UNIT: production-problem-solving ======
  // Lesson: reliability-incident-response
  {
    id: 'pps-rel-1',
    text: 'During an active incident, the first priority is typically to:',
    options: ['Write the postmortem immediately', 'Restore service safely and reduce user impact', 'Refactor code architecture', 'Start a new feature release'],
    correctAnswer: 1,
    explanation: 'Incident response prioritizes mitigation and user impact reduction before deep root-cause analysis.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'reliability-incident-response',
  },
  {
    id: 'pps-rel-2',
    text: 'Which signal is best for alerting on user-facing reliability?',
    options: ['Total number of commits', 'SLI/SLO metrics such as error rate, latency, and availability', 'Team calendar utilization', 'Average meeting duration'],
    correctAnswer: 1,
    explanation: 'SLI/SLO metrics map directly to user experience and service reliability.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'reliability-incident-response',
  },
  {
    id: 'pps-rel-3',
    text: 'A blameless postmortem mainly aims to:',
    options: ['Find one person to punish', 'Document causes, impacts, and preventative actions', 'Avoid any mention of failures', 'Skip action items to move faster'],
    correctAnswer: 1,
    explanation: 'Blameless postmortems improve systems and processes through actionable learning.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'reliability-incident-response',
  },
  {
    id: 'pps-rel-4',
    text: 'When debugging a production regression, a strong first step is:',
    options: ['Change multiple components at once', 'Compare recent changes and telemetry around the failure window', 'Wipe all caches without evidence', 'Disable logs for performance'],
    correctAnswer: 1,
    explanation: 'Time-bounded change correlation and telemetry inspection speed up root-cause isolation.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'reliability-incident-response',
  },
  {
    id: 'pps-rel-5',
    text: 'Why is runbook quality important in operations?',
    options: ['It reduces the need for metrics', 'It standardizes incident response and lowers time-to-mitigate', 'It replaces architecture diagrams', 'It prevents all outages'],
    correctAnswer: 1,
    explanation: 'Clear runbooks reduce confusion and improve consistency under operational pressure.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'reliability-incident-response',
  },

  // Lesson: cross-functional-execution
  {
    id: 'pps-cfx-1',
    text: 'When multiple teams depend on one delivery, the best planning approach is:',
    options: ['Independent timelines with no checkpoints', 'Shared milestones, owners, risks, and communication cadence', 'Only ad-hoc messaging', 'One final sync at launch'],
    correctAnswer: 1,
    explanation: 'Cross-functional programs succeed with explicit ownership, dependencies, and recurring alignment.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'cross-functional-execution',
  },
  {
    id: 'pps-cfx-2',
    text: 'A good way to prioritize backlog items with limited capacity is:',
    options: ['Oldest ticket first always', 'Impact, urgency, effort, and risk-based prioritization', 'Highest word-count requirement first', 'Random selection each sprint'],
    correctAnswer: 1,
    explanation: 'Structured prioritization improves ROI and reduces context switching.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'cross-functional-execution',
  },
  {
    id: 'pps-cfx-3',
    text: 'If a release is blocked by a critical dependency, the most practical response is:',
    options: ['Hide the blocker from stakeholders', 'Escalate early, propose options, and align on tradeoffs', 'Wait silently for resolution', 'Start unrelated refactoring'],
    correctAnswer: 1,
    explanation: 'Early communication with viable options enables faster and better decision-making.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'cross-functional-execution',
  },
  {
    id: 'pps-cfx-4',
    text: 'A clear launch readiness review should include:',
    options: ['Only feature demos', 'Rollback plan, ownership, metrics, and support readiness', 'No on-call assignment', 'Skipping risk assessment'],
    correctAnswer: 1,
    explanation: 'Launch quality depends on operational readiness, not just feature completeness.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'cross-functional-execution',
  },
  {
    id: 'pps-cfx-5',
    text: 'What is a healthy default when choosing between speed and reliability?',
    options: ['Always maximize speed', 'Always maximize reliability regardless context', 'Choose by risk tier and user impact with explicit tradeoff', 'Delay all launches indefinitely'],
    correctAnswer: 2,
    explanation: 'Balanced decisions require context, risk assessment, and transparent tradeoffs.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'real_world_execution',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'production-problem-solving',
    lessonId: 'cross-functional-execution',
  },
];
