// Part 1: Python & Programming, Probability & Statistics, Math Foundations
export const questionsPart1 = [
  // ====== UNIT: python-fundamentals ======
  // Lesson: python-basics
  {
    id: 'py-b-1',
    text: 'What is the output of `type([]) is list`?',
    options: ['True', 'False', 'TypeError', 'None'],
    correctAnswer: 0,
    explanation: 'The `type()` function returns the type of an object. `type([])` returns `<class "list">`, and comparing it with `is` to `list` returns True because they are the same object.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-2',
    text: 'Which of the following is an immutable data type in Python?',
    options: ['list', 'dict', 'set', 'tuple'],
    correctAnswer: 3,
    explanation: 'Tuples are immutable in Python - once created, their elements cannot be changed. Lists, dicts, and sets are all mutable.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-3',
    text: 'What does the `//` operator do in Python?',
    options: ['Regular division', 'Floor division', 'Modulo operation', 'Exponentiation'],
    correctAnswer: 1,
    explanation: 'The `//` operator performs floor (integer) division, rounding down to the nearest integer. For example, `7 // 2` returns `3`.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-4',
    text: 'What is the difference between `==` and `is` in Python?',
    options: ['They are identical', '`==` checks value equality, `is` checks identity (same object in memory)', '`is` checks value equality, `==` checks identity', '`==` only works with numbers'],
    correctAnswer: 1,
    explanation: '`==` compares the values of two objects, while `is` checks whether two references point to the exact same object in memory. For example, `[1,2] == [1,2]` is True, but `[1,2] is [1,2]` is False.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-5',
    text: 'What will `len({1, 2, 2, 3, 3, 3})` return?',
    options: ['6', '3', '1', 'TypeError'],
    correctAnswer: 1,
    explanation: 'Sets in Python contain only unique elements. `{1, 2, 2, 3, 3, 3}` becomes `{1, 2, 3}`, which has length 3.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-6',
    text: 'What is the time complexity of checking membership in a Python set vs. a list?',
    options: ['Both O(n)', 'Set: O(1) average, List: O(n)', 'Set: O(n), List: O(1)', 'Both O(1)'],
    correctAnswer: 1,
    explanation: 'Sets use hash tables, so membership checking (`x in set`) is O(1) on average. Lists require linear search, making it O(n).',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-7',
    text: 'What does the `zip()` function do in Python?',
    options: ['Compresses files', 'Creates an iterator of tuples from multiple iterables', 'Merges two dictionaries', 'Sorts multiple lists simultaneously'],
    correctAnswer: 1,
    explanation: '`zip()` takes multiple iterables and returns an iterator of tuples, where each tuple contains elements from each iterable at the same position. Example: `zip([1,2], ["a","b"])` yields `(1,"a"), (2,"b")`.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-8',
    text: 'What is a list comprehension and what is its advantage over a for loop?',
    options: ['It is slower but more readable', 'It is generally faster and more concise than equivalent for loops', 'It only works with numbers', 'It creates tuples instead of lists'],
    correctAnswer: 1,
    explanation: 'List comprehensions are syntactic sugar that is both more concise and generally faster than for loops because the iteration is optimized in C under the hood. Example: `[x**2 for x in range(10)]`.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-9',
    text: 'What is the Global Interpreter Lock (GIL) in CPython?',
    options: ['A security feature that prevents unauthorized code execution', 'A mutex that protects access to Python objects, preventing multiple threads from executing Python bytecode simultaneously', 'A garbage collection mechanism', 'A way to lock global variables'],
    correctAnswer: 1,
    explanation: 'The GIL is a mutex in CPython that allows only one thread to execute Python bytecode at a time. This means CPU-bound multithreaded programs may not see performance benefits. For CPU-bound parallelism, use multiprocessing instead.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },
  {
    id: 'py-b-10',
    text: 'In Python, what is the difference between shallow copy and deep copy?',
    options: ['There is no difference', 'Shallow copy creates a new object but references the same nested objects; deep copy recursively copies all objects', 'Deep copy is always faster', 'Shallow copy only works with lists'],
    correctAnswer: 1,
    explanation: 'A shallow copy (`copy.copy()`) creates a new object but inserts references to the same nested objects. A deep copy (`copy.deepcopy()`) creates a new object and recursively copies all nested objects, creating fully independent copies.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-basics',
  },

  // Lesson: python-advanced
  {
    id: 'py-a-1',
    text: 'What is a Python generator and how does it differ from a regular function?',
    options: ['Generators run faster than functions', 'Generators use `yield` to produce values lazily, maintaining state between calls, while functions use `return` and execute completely', 'Generators can only produce numbers', 'There is no difference'],
    correctAnswer: 1,
    explanation: 'Generators use `yield` instead of `return` to produce a sequence of values lazily (one at a time). They maintain their state between calls and are memory-efficient for large datasets since they do not store all values in memory at once.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-2',
    text: 'What is a decorator in Python?',
    options: ['A design pattern for UI elements', 'A function that takes another function and extends its behavior without modifying it', 'A type of class inheritance', 'A way to add comments to code'],
    correctAnswer: 1,
    explanation: 'A decorator is a function that wraps another function to extend or modify its behavior. They use the `@decorator_name` syntax and are commonly used for logging, authentication, caching, etc.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-3',
    text: 'What is the `__init__` method in a Python class?',
    options: ['A destructor method', 'The constructor method called when an object is created', 'A static method', 'A method that initializes the Python interpreter'],
    correctAnswer: 1,
    explanation: '`__init__` is the constructor (initializer) method in Python classes. It is automatically called when a new instance is created and is used to set up instance attributes.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-4',
    text: 'What is the difference between `@staticmethod` and `@classmethod`?',
    options: ['They are the same thing', '`@staticmethod` does not receive any implicit first argument; `@classmethod` receives the class as its first argument', '`@classmethod` is faster', '`@staticmethod` can only be used in abstract classes'],
    correctAnswer: 1,
    explanation: '`@staticmethod` creates a method that does not receive any implicit first argument (no `self` or `cls`). `@classmethod` receives the class itself as the first argument (`cls`), which is useful for factory methods or methods that need to access class-level attributes.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-5',
    text: 'What are `*args` and `**kwargs` used for?',
    options: ['Error handling', '`*args` collects positional arguments as a tuple, `**kwargs` collects keyword arguments as a dictionary', 'Defining global variables', 'Type annotations'],
    correctAnswer: 1,
    explanation: '`*args` allows a function to accept any number of positional arguments (packed into a tuple). `**kwargs` allows a function to accept any number of keyword arguments (packed into a dictionary). They enable flexible function signatures.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-6',
    text: 'What is the purpose of `__slots__` in a Python class?',
    options: ['To define database fields', 'To restrict attribute creation and reduce memory usage by avoiding per-instance __dict__', 'To create time slots for scheduling', 'To define method signatures'],
    correctAnswer: 1,
    explanation: '`__slots__` restricts a class to only the attributes listed, preventing the creation of a `__dict__` for each instance. This saves significant memory when creating many instances and can speed up attribute access.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-7',
    text: 'What is a context manager in Python and how is it typically used?',
    options: ['A project management tool', 'An object that defines `__enter__` and `__exit__` methods, commonly used with `with` statements for resource management', 'A debugging tool', 'A way to manage environment variables'],
    correctAnswer: 1,
    explanation: 'Context managers implement `__enter__` and `__exit__` methods and are used with `with` statements. They ensure proper acquisition and release of resources (files, locks, connections). Example: `with open("file.txt") as f:`.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-8',
    text: 'What is monkey patching in Python?',
    options: ['A code obfuscation technique', 'Dynamically modifying a class or module at runtime', 'A testing framework', 'An optimization technique'],
    correctAnswer: 1,
    explanation: 'Monkey patching is the dynamic modification of a class or module at runtime. While it can be useful for testing (mocking), it should be used sparingly in production as it can make code harder to debug and maintain.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-9',
    text: 'What is the Method Resolution Order (MRO) in Python?',
    options: ['The order methods are defined in a file', 'The order in which Python searches for methods in a class hierarchy, using C3 linearization algorithm', 'The order of function calls in a stack trace', 'Alphabetical ordering of methods'],
    correctAnswer: 1,
    explanation: 'MRO determines the order in which base classes are searched when executing a method. Python uses the C3 linearization algorithm to determine this order, which ensures a consistent and predictable resolution in complex multiple inheritance scenarios.',
    difficulty: 'very_hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },
  {
    id: 'py-a-10',
    text: 'What is the difference between `multiprocessing` and `threading` in Python?',
    options: ['They are identical', '`multiprocessing` creates separate processes bypassing the GIL for true parallelism; `threading` shares the same process and is limited by the GIL for CPU-bound tasks', '`threading` is always faster', '`multiprocessing` only works on Linux'],
    correctAnswer: 1,
    explanation: '`threading` uses threads within a single process, sharing memory but limited by the GIL for CPU-bound work. `multiprocessing` creates separate processes, each with its own GIL, enabling true parallelism for CPU-bound tasks but with higher memory overhead.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer', 'mlops_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'python-advanced',
  },

  // Lesson: numpy-pandas
  {
    id: 'np-1',
    text: 'What is broadcasting in NumPy?',
    options: ['Sending arrays over a network', 'A mechanism that allows NumPy to perform operations on arrays of different shapes by automatically expanding dimensions', 'Converting arrays to lists', 'A way to print arrays'],
    correctAnswer: 1,
    explanation: 'Broadcasting allows NumPy to perform element-wise operations on arrays with different shapes. Smaller arrays are "broadcast" across larger arrays so they have compatible shapes. For example, adding a scalar to an array adds it to every element.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-2',
    text: 'What is the difference between `pd.merge()` and `pd.concat()`?',
    options: ['They are the same', '`merge()` joins DataFrames on columns/indices (like SQL joins); `concat()` stacks DataFrames along an axis', '`concat()` is for SQL-like joins', '`merge()` only works vertically'],
    correctAnswer: 1,
    explanation: '`pd.merge()` performs database-style joins on columns or indices (inner, outer, left, right). `pd.concat()` concatenates DataFrames along a particular axis (stacking rows or columns). They serve different purposes.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-3',
    text: 'What does `df.groupby("col").agg({"val": ["mean", "sum"]})` do?',
    options: ['Filters rows', 'Groups the DataFrame by "col" and computes both mean and sum of "val" for each group', 'Sorts the DataFrame', 'Renames columns'],
    correctAnswer: 1,
    explanation: 'This groups the DataFrame by unique values in "col", then computes multiple aggregate functions (mean and sum) on the "val" column for each group, returning a multi-level column DataFrame.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-4',
    text: 'How do you handle missing values in a Pandas DataFrame?',
    options: ['Missing values cannot be handled', 'Using methods like `fillna()`, `dropna()`, `interpolate()`, or `isna()` for detection', 'By converting to a list first', 'Missing values are automatically removed'],
    correctAnswer: 1,
    explanation: 'Pandas provides several methods: `isna()`/`isnull()` to detect missing values, `dropna()` to remove rows/columns with NaN, `fillna()` to fill with specific values, and `interpolate()` for interpolation-based filling.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-5',
    text: 'What is vectorization in NumPy and why is it important?',
    options: ['Converting data to vectors for visualization', 'Performing operations on entire arrays at once using optimized C code instead of Python loops, resulting in significant speedups', 'A compression technique', 'Converting images to arrays'],
    correctAnswer: 1,
    explanation: 'Vectorization means performing operations on entire arrays at once using NumPy\'s underlying C implementation, avoiding slow Python loops. This can be 10-100x faster than equivalent Python loops for numerical computations.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-6',
    text: 'What is the difference between `.loc[]` and `.iloc[]` in Pandas?',
    options: ['They are identical', '`.loc[]` uses label-based indexing; `.iloc[]` uses integer position-based indexing', '`.iloc[]` is for columns only', '`.loc[]` is deprecated'],
    correctAnswer: 1,
    explanation: '`.loc[]` accesses data by label/name (e.g., `df.loc["row_name", "col_name"]`). `.iloc[]` accesses data by integer position (e.g., `df.iloc[0, 1]`). This is a fundamental Pandas distinction.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-7',
    text: 'What does `np.einsum("ij,jk->ik", A, B)` compute?',
    options: ['Element-wise multiplication', 'Matrix multiplication of A and B', 'Transpose of A', 'Determinant of A'],
    correctAnswer: 1,
    explanation: '`np.einsum` uses Einstein summation convention. "ij,jk->ik" means: for matrices A (i×j) and B (j×k), sum over the shared index j to produce result (i×k). This is matrix multiplication.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-8',
    text: 'What is the `apply()` method in Pandas used for?',
    options: ['Applying CSS styles', 'Applying a function along an axis of the DataFrame or to each element of a Series', 'Merging DataFrames', 'Sorting data'],
    correctAnswer: 1,
    explanation: '`apply()` applies a function along an axis of a DataFrame (rows or columns) or to each element of a Series. It is versatile but can be slow for large datasets compared to vectorized operations.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-9',
    text: 'What is a Pandas MultiIndex and when would you use it?',
    options: ['An index with multiple data types', 'A hierarchical index that allows multiple levels of indexing for higher-dimensional data in a 2D structure', 'An index that spans multiple DataFrames', 'A backup index system'],
    correctAnswer: 1,
    explanation: 'MultiIndex (hierarchical index) allows you to have multiple levels of row or column indices, enabling you to work with higher-dimensional data in a 2D DataFrame. Useful for grouped/pivoted data.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },
  {
    id: 'np-10',
    text: 'Why should you avoid chained indexing (e.g., `df["col"][0] = val`) in Pandas?',
    options: ['It is too slow', 'It may create a copy instead of a view, leading to the SettingWithCopyWarning and potentially not modifying the original DataFrame', 'It causes memory leaks', 'It is deprecated syntax'],
    correctAnswer: 1,
    explanation: 'Chained indexing can create a temporary copy, so assignments may not modify the original DataFrame. This triggers the SettingWithCopyWarning. Use `.loc[]` or `.iloc[]` for safe assignments: `df.loc[0, "col"] = val`.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'python-fundamentals',
    lessonId: 'numpy-pandas',
  },

  // ====== UNIT: probability-statistics ======
  // Lesson: prob-basics
  {
    id: 'prob-1',
    text: 'What is Bayes\' Theorem?',
    options: ['P(A|B) = P(B|A) × P(B) / P(A)', 'P(A|B) = P(B|A) × P(A) / P(B)', 'P(A|B) = P(A) × P(B)', 'P(A|B) = P(A) + P(B)'],
    correctAnswer: 1,
    explanation: 'Bayes\' Theorem states P(A|B) = P(B|A) × P(A) / P(B). It describes how to update the probability of a hypothesis given new evidence. P(A) is the prior, P(B|A) is the likelihood, and P(B) is the marginal likelihood.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-2',
    text: 'What is the Law of Total Probability?',
    options: ['P(A) = 1 - P(A\')', 'P(A) = Σ P(A|Bᵢ) × P(Bᵢ) for all mutually exclusive and exhaustive events Bᵢ', 'P(A) = P(A∪B) - P(B)', 'P(A) = P(A) × P(B)'],
    correctAnswer: 1,
    explanation: 'The Law of Total Probability states that if B₁, B₂, ..., Bₙ are mutually exclusive and exhaustive events, then P(A) = Σ P(A|Bᵢ) × P(Bᵢ). It allows computing P(A) by conditioning on all possible scenarios.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-3',
    text: 'Two events are independent if and only if:',
    options: ['P(A ∩ B) = P(A) + P(B)', 'P(A ∩ B) = P(A) × P(B)', 'P(A|B) = P(B)', 'P(A ∪ B) = 0'],
    correctAnswer: 1,
    explanation: 'Two events A and B are independent if and only if P(A ∩ B) = P(A) × P(B). Equivalently, P(A|B) = P(A), meaning knowing B occurred does not change the probability of A.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-4',
    text: 'What is the expected value of a fair six-sided die roll?',
    options: ['3', '3.5', '4', '3.67'],
    correctAnswer: 1,
    explanation: 'E[X] = (1+2+3+4+5+6)/6 = 21/6 = 3.5. The expected value is the probability-weighted average of all possible outcomes.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-5',
    text: 'If you flip a fair coin 10 times, what is the probability of getting exactly 7 heads?',
    options: ['0.117', '0.172', '0.070', '0.200'],
    correctAnswer: 0,
    explanation: 'This follows a Binomial distribution. P(X=7) = C(10,7) × (0.5)^7 × (0.5)^3 = 120 × (1/1024) ≈ 0.117. We use the binomial probability formula with n=10, k=7, p=0.5.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-6',
    text: 'What is conditional probability P(A|B)?',
    options: ['The probability of A or B', 'The probability of A given that B has occurred, equal to P(A∩B)/P(B)', 'The probability of B given A', 'P(A) × P(B)'],
    correctAnswer: 1,
    explanation: 'Conditional probability P(A|B) = P(A∩B)/P(B) represents the probability of event A occurring given that event B has already occurred. It is only defined when P(B) > 0.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-7',
    text: 'A diagnostic test has 95% sensitivity and 90% specificity. If the disease prevalence is 1%, what is the approximate probability a positive test result is a true positive?',
    options: ['95%', '90%', 'About 8.8%', 'About 50%'],
    correctAnswer: 2,
    explanation: 'Using Bayes\' Theorem: P(Disease|+) = (0.95 × 0.01) / (0.95 × 0.01 + 0.10 × 0.99) = 0.0095 / 0.1085 ≈ 8.8%. Despite high sensitivity/specificity, low prevalence means most positives are false positives.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-8',
    text: 'What is the Monty Hall problem\'s optimal strategy?',
    options: ['Stay with your original choice (1/2 chance)', 'It does not matter (50/50 either way)', 'Always switch doors (2/3 chance of winning)', 'Choose randomly (1/3 chance)'],
    correctAnswer: 2,
    explanation: 'In the Monty Hall problem, switching gives a 2/3 probability of winning. Your original choice has 1/3 probability, and since the host always reveals a goat, the remaining door has 2/3 probability.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-9',
    text: 'What does it mean for two random variables to be uncorrelated but not independent?',
    options: ['This is impossible; uncorrelated always means independent', 'Their linear correlation is zero, but they may have nonlinear dependencies', 'They have the same distribution', 'They always equal each other'],
    correctAnswer: 1,
    explanation: 'Uncorrelated means Cov(X,Y) = 0, meaning no linear relationship. However, there can still be nonlinear dependencies. For example, if X ~ Uniform(-1,1) and Y = X², then Cov(X,Y) = 0 but Y is completely determined by X.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },
  {
    id: 'prob-10',
    text: 'You have two children. One of them is a boy. What is the probability that both children are boys?',
    options: ['1/2', '1/3', '1/4', '2/3'],
    correctAnswer: 1,
    explanation: 'The sample space of two children is {BB, BG, GB, GG}. Given at least one boy, we eliminate GG, leaving {BB, BG, GB}. P(BB | at least one B) = 1/3. This is a classic conditional probability problem.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'prob-basics',
  },

  // Lesson: distributions
  {
    id: 'dist-1',
    text: 'Which distribution models the number of successes in a fixed number of independent Bernoulli trials?',
    options: ['Normal distribution', 'Poisson distribution', 'Binomial distribution', 'Exponential distribution'],
    correctAnswer: 2,
    explanation: 'The Binomial distribution models the number of successes in n independent Bernoulli trials, each with probability p. Its PMF is P(X=k) = C(n,k) × p^k × (1-p)^(n-k).',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-2',
    text: 'What is the Central Limit Theorem (CLT)?',
    options: ['All data is normally distributed', 'The sum (or average) of a large number of independent random variables tends toward a normal distribution, regardless of the original distribution', 'The mean always equals the median', 'Large samples are always representative'],
    correctAnswer: 1,
    explanation: 'The CLT states that the sampling distribution of the sample mean approaches a normal distribution as sample size increases, regardless of the population\'s distribution (given finite variance). This is fundamental to statistical inference.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-3',
    text: 'When would you use a Poisson distribution?',
    options: ['For continuous data', 'For modeling the number of events occurring in a fixed interval of time/space when events are independent and occur at a constant average rate', 'For binary outcomes', 'For modeling time between events'],
    correctAnswer: 1,
    explanation: 'The Poisson distribution models the count of events in a fixed interval when events occur independently at a constant average rate λ. Examples: number of emails per hour, website visits per day.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-4',
    text: 'What characterizes a normal (Gaussian) distribution?',
    options: ['It is always positively skewed', 'It is symmetric and bell-shaped, fully defined by its mean (μ) and variance (σ²), with about 68% of data within 1 standard deviation', 'It can only have positive values', 'It has no defined variance'],
    correctAnswer: 1,
    explanation: 'The normal distribution is symmetric, bell-shaped, and parameterized by mean μ and variance σ². The 68-95-99.7 rule states ~68% of data falls within ±1σ, ~95% within ±2σ, and ~99.7% within ±3σ of the mean.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-5',
    text: 'What is the relationship between the Exponential and Poisson distributions?',
    options: ['They are unrelated', 'The Exponential models the time between Poisson events; if events arrive at rate λ, time between events is Exponential(λ)', 'They are the same distribution', 'The Exponential is the discrete version of Poisson'],
    correctAnswer: 1,
    explanation: 'If events follow a Poisson process with rate λ, then the time between consecutive events follows an Exponential distribution with rate parameter λ. They are dual perspectives of the same process.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-6',
    text: 'What is the difference between a probability density function (PDF) and a probability mass function (PMF)?',
    options: ['They are the same thing', 'PDF is for continuous random variables (probability of intervals); PMF is for discrete random variables (probability of specific values)', 'PMF is for continuous variables', 'PDF always sums to 1'],
    correctAnswer: 1,
    explanation: 'A PMF gives the probability that a discrete random variable equals a specific value: P(X=x). A PDF gives the probability density for continuous variables; the probability of an interval is the integral of the PDF over that interval.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-7',
    text: 'What distribution would you use to model the probability of an event happening for the first time on the k-th trial?',
    options: ['Binomial', 'Geometric', 'Normal', 'Uniform'],
    correctAnswer: 1,
    explanation: 'The Geometric distribution models the number of trials until the first success. P(X=k) = (1-p)^(k-1) × p, where p is the probability of success on each trial.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-8',
    text: 'What is a QQ-plot used for?',
    options: ['Comparing two qualitative variables', 'Assessing whether data follows a theoretical distribution by plotting quantiles against each other', 'Plotting Q-values from hypothesis testing', 'Visualizing query results'],
    correctAnswer: 1,
    explanation: 'A QQ (Quantile-Quantile) plot compares quantiles of your data against quantiles of a theoretical distribution (often Normal). If points fall along the diagonal line, the data approximately follows that distribution.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-9',
    text: 'What is the Beta distribution commonly used for in machine learning?',
    options: ['Modeling count data', 'Modeling probabilities and proportions (values between 0 and 1), commonly used as a prior in Bayesian inference', 'Modeling time series', 'Modeling categorical data'],
    correctAnswer: 1,
    explanation: 'The Beta distribution is defined on [0,1] and is characterized by parameters α and β. It is commonly used as a conjugate prior for Bernoulli/Binomial likelihoods in Bayesian inference, making it ideal for modeling uncertainty about probabilities.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },
  {
    id: 'dist-10',
    text: 'What is the Law of Large Numbers?',
    options: ['Large numbers are always normally distributed', 'As sample size increases, the sample mean converges to the true population mean', 'Large datasets always have less variance', 'Statistical tests require at least 10,000 samples'],
    correctAnswer: 1,
    explanation: 'The Law of Large Numbers states that as n→∞, the sample average converges to the expected value (population mean). There are weak and strong versions, but the core idea is that more data gives better estimates.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'distributions',
  },

  // Lesson: hypothesis-testing
  {
    id: 'hyp-1',
    text: 'What is a p-value?',
    options: ['The probability that the null hypothesis is true', 'The probability of observing results at least as extreme as the observed data, assuming the null hypothesis is true', 'The probability of making a Type I error', 'The probability the alternative hypothesis is true'],
    correctAnswer: 1,
    explanation: 'A p-value is the probability of obtaining test results at least as extreme as the observed results, under the assumption that the null hypothesis is true. It is NOT the probability that H₀ is true.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-2',
    text: 'What is the difference between Type I and Type II errors?',
    options: ['Type I is a false positive (rejecting true H₀); Type II is a false negative (failing to reject false H₀)', 'Type I is more serious than Type II always', 'Type I is a false negative; Type II is a false positive', 'They are the same thing'],
    correctAnswer: 0,
    explanation: 'Type I error (α): Rejecting a true null hypothesis (false positive). Type II error (β): Failing to reject a false null hypothesis (false negative). The power of a test is 1 - β.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-3',
    text: 'What is the significance level (α) in hypothesis testing?',
    options: ['The probability of a Type II error', 'The maximum probability of rejecting the null hypothesis when it is true (typically 0.05)', 'The p-value threshold for accepting H₁', 'The sample size required'],
    correctAnswer: 1,
    explanation: 'The significance level α (typically 0.05) is the threshold for the p-value below which we reject the null hypothesis. It represents the maximum acceptable probability of a Type I error (false positive).',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-4',
    text: 'When would you use a chi-squared test?',
    options: ['To compare means of two groups', 'To test for independence between categorical variables or goodness-of-fit to an expected distribution', 'To test normality', 'To compare variances of two groups'],
    correctAnswer: 1,
    explanation: 'Chi-squared tests are used for: (1) Test of independence between categorical variables, and (2) Goodness-of-fit testing to see if observed frequencies match expected frequencies. The test statistic follows a chi-squared distribution.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-5',
    text: 'What is the Bonferroni correction?',
    options: ['A way to increase statistical power', 'Adjusting the significance level by dividing α by the number of comparisons to control the family-wise error rate', 'A normalization technique', 'A method to reduce sample size'],
    correctAnswer: 1,
    explanation: 'When performing multiple hypothesis tests, the Bonferroni correction divides the significance level α by the number of tests (m), using α/m for each individual test. This controls the family-wise error rate but is conservative.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-6',
    text: 'What is statistical power?',
    options: ['The probability of rejecting H₀ when it is true', 'The probability of correctly rejecting H₀ when it is false (1 - β)', 'The significance level', 'The effect size'],
    correctAnswer: 1,
    explanation: 'Statistical power = 1 - β, where β is the Type II error rate. It is the probability of correctly rejecting a false null hypothesis. Power increases with sample size, effect size, and significance level.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-7',
    text: 'When should you use a paired t-test vs. an independent two-sample t-test?',
    options: ['They are interchangeable', 'Paired when the same subjects are measured twice (before/after); independent when two separate groups are compared', 'Independent is always better', 'Paired is only for large samples'],
    correctAnswer: 1,
    explanation: 'A paired t-test is used when observations are naturally paired (same subject before/after, matched samples). An independent two-sample t-test is used when comparing two separate, unrelated groups.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-8',
    text: 'What is the difference between parametric and non-parametric tests?',
    options: ['Parametric tests are always more powerful', 'Parametric tests assume a specific distribution (usually normal); non-parametric tests make fewer distributional assumptions', 'Non-parametric tests require larger samples', 'There is no practical difference'],
    correctAnswer: 1,
    explanation: 'Parametric tests (t-test, ANOVA) assume data follows a specific distribution. Non-parametric tests (Mann-Whitney U, Kruskal-Wallis) make fewer assumptions about the data distribution and are useful when parametric assumptions are violated.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-9',
    text: 'What is a confidence interval?',
    options: ['The range where the true parameter definitely lies', 'A range of values that, when constructed repeatedly from random samples, would contain the true parameter a specified percentage of the time', 'The range of the data', 'The standard deviation of the mean'],
    correctAnswer: 1,
    explanation: 'A 95% confidence interval means that if you repeated the sampling process many times, about 95% of the constructed intervals would contain the true population parameter. It does NOT mean there is a 95% probability the parameter is in this specific interval.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },
  {
    id: 'hyp-10',
    text: 'What is the multiple testing problem and why does it matter in data science?',
    options: ['Running the same test multiple times', 'When testing many hypotheses simultaneously, the probability of at least one false positive increases dramatically, requiring correction methods like Bonferroni or FDR', 'Testing with multiple datasets', 'Using multiple statistical software packages'],
    correctAnswer: 1,
    explanation: 'With m independent tests at α=0.05, the probability of at least one false positive is 1-(1-α)^m. With 20 tests, this is ~64%. Methods like Bonferroni correction (conservative) or Benjamini-Hochberg (FDR control) address this.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'probability-statistics',
    lessonId: 'hypothesis-testing',
  },

  // ====== UNIT: math-foundations ======
  // Lesson: linear-algebra
  {
    id: 'la-1',
    text: 'What are eigenvalues and eigenvectors?',
    options: ['Types of matrices', 'For a matrix A, an eigenvector v satisfies Av = λv, where λ is the corresponding eigenvalue (a scalar)', 'Eigenvectors are always orthogonal', 'Eigenvalues are always positive'],
    correctAnswer: 1,
    explanation: 'For a square matrix A, an eigenvector v is a non-zero vector such that Av = λv, where λ is the eigenvalue. The eigenvector\'s direction is unchanged by the transformation; the eigenvalue is the scaling factor.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-2',
    text: 'What is the purpose of Singular Value Decomposition (SVD)?',
    options: ['Only for image compression', 'Factorizing a matrix M into UΣVᵀ, used for dimensionality reduction, noise reduction, and matrix approximation', 'Finding the inverse of a matrix', 'Solving systems of linear equations only'],
    correctAnswer: 1,
    explanation: 'SVD decomposes any matrix M (m×n) into M = UΣVᵀ, where U and V are orthogonal matrices and Σ is diagonal with singular values. It is used in PCA, recommender systems, image compression, and low-rank approximation.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-3',
    text: 'What does it mean for a matrix to be positive semi-definite?',
    options: ['All elements are positive', 'For all vectors x, xᵀAx ≥ 0, equivalently all eigenvalues are non-negative', 'The determinant is positive', 'The matrix is square'],
    correctAnswer: 1,
    explanation: 'A symmetric matrix A is positive semi-definite if xᵀAx ≥ 0 for all vectors x. Equivalently, all its eigenvalues are non-negative. Covariance matrices are always positive semi-definite.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-4',
    text: 'What is the rank of a matrix?',
    options: ['The number of rows', 'The maximum number of linearly independent rows (or columns)', 'The determinant', 'The trace'],
    correctAnswer: 1,
    explanation: 'The rank of a matrix is the maximum number of linearly independent rows (or equivalently, columns). It tells you the dimension of the column space (or row space). A full-rank matrix has rank equal to the minimum of its dimensions.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-5',
    text: 'Why is the dot product of two vectors important in machine learning?',
    options: ['It is not used in ML', 'It measures similarity between vectors, is used in cosine similarity, attention mechanisms, kernel methods, and forms the basis of many ML operations', 'It only measures distance', 'It only works in 2D'],
    correctAnswer: 1,
    explanation: 'The dot product measures the alignment between vectors. It underpins cosine similarity, attention scores in transformers, kernel methods in SVMs, and is the basic operation in neural network layers (weight × input).',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-6',
    text: 'What is the difference between L1 and L2 norms?',
    options: ['They always give the same result', 'L1 norm is the sum of absolute values (Manhattan distance); L2 norm is the square root of sum of squares (Euclidean distance)', 'L1 is always larger than L2', 'L2 norm is for matrices only'],
    correctAnswer: 1,
    explanation: 'L1 norm (||x||₁) = Σ|xᵢ| (Manhattan distance). L2 norm (||x||₂) = √(Σxᵢ²) (Euclidean distance). In ML, L1 regularization promotes sparsity while L2 regularization promotes small, distributed weights.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-7',
    text: 'What is the trace of a matrix?',
    options: ['The product of diagonal elements', 'The sum of the diagonal elements, which equals the sum of the eigenvalues', 'The number of non-zero elements', 'The determinant of the matrix'],
    correctAnswer: 1,
    explanation: 'The trace of a square matrix is the sum of its diagonal elements: tr(A) = Σaᵢᵢ. An important property is that the trace equals the sum of eigenvalues. It is used in various ML contexts including matrix calculus.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-8',
    text: 'How is PCA related to eigenvalue decomposition?',
    options: ['They are unrelated', 'PCA finds principal components by computing eigenvectors of the covariance matrix; eigenvalues indicate the variance explained by each component', 'PCA uses eigenvalues but not eigenvectors', 'Eigendecomposition is an alternative to PCA'],
    correctAnswer: 1,
    explanation: 'PCA computes the covariance matrix of the data, then finds its eigenvectors (principal components) and eigenvalues (variance explained). The eigenvector with the largest eigenvalue points in the direction of maximum variance.',
    difficulty: 'hard',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-9',
    text: 'What is the determinant of a matrix and what does it signify?',
    options: ['The sum of all elements', 'A scalar value that indicates the scaling factor of the linear transformation; if zero, the matrix is singular (non-invertible)', 'The number of pivots', 'Always positive for square matrices'],
    correctAnswer: 1,
    explanation: 'The determinant is a scalar that describes the scaling factor of the transformation represented by the matrix. |det(A)| gives the volume scaling factor. If det(A) = 0, the matrix is singular (non-invertible), meaning it maps to a lower dimension.',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },
  {
    id: 'la-10',
    text: 'What is an orthogonal matrix and why is it useful?',
    options: ['A matrix with all zeros off-diagonal', 'A square matrix whose columns (and rows) are orthonormal vectors, satisfying AᵀA = I; its inverse equals its transpose', 'Any diagonal matrix', 'A matrix with orthogonal rows only'],
    correctAnswer: 1,
    explanation: 'An orthogonal matrix Q has orthonormal columns: QᵀQ = QQᵀ = I, so Q⁻¹ = Qᵀ. This makes inversion trivial. Orthogonal matrices preserve lengths and angles, making them important in SVD, rotations, and numerical stability.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'linear-algebra',
  },

  // Lesson: calculus-optimization
  {
    id: 'calc-1',
    text: 'What is gradient descent?',
    options: ['A sorting algorithm', 'An iterative optimization algorithm that updates parameters in the direction of the negative gradient to minimize a loss function', 'A type of neural network', 'A regularization technique'],
    correctAnswer: 1,
    explanation: 'Gradient descent iteratively updates parameters: θ = θ - α∇L(θ), where α is the learning rate and ∇L(θ) is the gradient of the loss function. It moves in the steepest descent direction to find a minimum.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-2',
    text: 'What is the difference between batch, stochastic, and mini-batch gradient descent?',
    options: ['They all use the full dataset', 'Batch uses all data per update, SGD uses one sample, mini-batch uses a subset; they differ in convergence speed and stability', 'SGD is always fastest', 'Mini-batch is only for deep learning'],
    correctAnswer: 1,
    explanation: 'Batch GD computes the gradient over the entire dataset (stable but slow). SGD uses one random sample (fast but noisy). Mini-batch uses a small random subset (balanced approach, most commonly used in practice).',
    difficulty: 'medium',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-3',
    text: 'What is the chain rule in calculus and why is it important for deep learning?',
    options: ['A rule about Markov chains', 'It computes the derivative of composite functions: d/dx f(g(x)) = f\'(g(x))·g\'(x), forming the basis of backpropagation', 'It only applies to linear functions', 'A rule for chaining models together'],
    correctAnswer: 1,
    explanation: 'The chain rule states d/dx f(g(x)) = f\'(g(x))·g\'(x). In deep learning, backpropagation applies the chain rule to compute gradients through layers of composed functions, enabling efficient gradient computation for parameter updates.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-4',
    text: 'What is a saddle point and why is it problematic in optimization?',
    options: ['A global minimum', 'A point where the gradient is zero but it is neither a local minimum nor maximum; optimization can stall here', 'A point with maximum gradient', 'Only exists in 1D functions'],
    correctAnswer: 1,
    explanation: 'A saddle point has zero gradient but is a minimum along some dimensions and a maximum along others. In high-dimensional optimization (common in deep learning), saddle points are more common than local minima and can slow training.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-5',
    text: 'What is the learning rate and what happens if it is too large or too small?',
    options: ['It does not matter', 'The step size in gradient descent; too large causes divergence/oscillation, too small causes extremely slow convergence', 'It should always be 0.01', 'It is the same as the epoch count'],
    correctAnswer: 1,
    explanation: 'The learning rate (α) controls the step size in gradient updates. Too large: overshoots minima, may diverge. Too small: converges very slowly, may get stuck. Finding the right learning rate (or using adaptive methods) is crucial for training.',
    difficulty: 'easy',
    roles: ['data_scientist', 'ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['startup', 'midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-6',
    text: 'What is convex optimization and why is it desirable?',
    options: ['Optimization that always diverges', 'Optimization of convex functions where any local minimum is also a global minimum, guaranteeing optimal solutions', 'Only applies to linear functions', 'A type of gradient descent'],
    correctAnswer: 1,
    explanation: 'A convex function has the property that any local minimum is the global minimum. This means gradient descent is guaranteed to find the optimal solution. Linear regression has a convex loss, but neural networks generally do not.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-7',
    text: 'What is the Jacobian matrix?',
    options: ['A type of regularization matrix', 'The matrix of all first-order partial derivatives of a vector-valued function', 'The inverse of the Hessian', 'A diagonal matrix of gradients'],
    correctAnswer: 1,
    explanation: 'The Jacobian of a function f: ℝⁿ → ℝᵐ is an m×n matrix where Jᵢⱼ = ∂fᵢ/∂xⱼ. It generalizes the gradient to vector-valued functions and is essential in backpropagation through layers and in computing transformations.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-8',
    text: 'How does the Adam optimizer improve upon standard SGD?',
    options: ['It uses a fixed learning rate', 'It combines momentum (first moment) and RMSProp (second moment) to adapt learning rates per parameter, with bias correction', 'It only works for convex problems', 'It removes the need for a learning rate'],
    correctAnswer: 1,
    explanation: 'Adam (Adaptive Moment Estimation) maintains exponential moving averages of the gradient (first moment, like momentum) and squared gradient (second moment, like RMSProp). It adapts the learning rate for each parameter and includes bias correction for early steps.',
    difficulty: 'hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-9',
    text: 'What is the Hessian matrix and what does it tell us?',
    options: ['A matrix of first derivatives', 'The matrix of second-order partial derivatives, indicating the curvature of the loss landscape and useful for determining convergence properties', 'The same as the Jacobian', 'Only applicable to 2D functions'],
    correctAnswer: 1,
    explanation: 'The Hessian is the matrix of second partial derivatives: Hᵢⱼ = ∂²f/∂xᵢ∂xⱼ. It captures curvature information: positive definite Hessian at a critical point indicates a local minimum. Newton\'s method uses the Hessian for faster convergence.',
    difficulty: 'very_hard',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
  {
    id: 'calc-10',
    text: 'What is the vanishing gradient problem?',
    options: ['Gradients becoming too large', 'Gradients becoming exponentially small in deep networks, making early layers learn very slowly or not at all', 'A problem with learning rate scheduling', 'Only occurs in CNNs'],
    correctAnswer: 1,
    explanation: 'In deep networks, gradients can become exponentially small as they are backpropagated through many layers (especially with sigmoid/tanh activations). This prevents early layers from learning. Solutions include ReLU activation, residual connections, and careful initialization.',
    difficulty: 'medium',
    roles: ['ml_engineer', 'ai_engineer'],
    category: 'technical',
    companySizes: ['midsize', 'large', 'faang'],
    unitId: 'math-foundations',
    lessonId: 'calculus-optimization',
  },
];
